<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.11.2 by Michael Rose
  Copyright 2013-2018 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE.txt
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Machine Learning - Geospatial Workbook</title>
<meta name="description" content="Tutorial on Informatics for Geospatial Information">


  <meta name="author" content="Kerrie Geil">


<meta property="og:type" content="website">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Geospatial Workbook">
<meta property="og:title" content="Machine Learning">
<meta property="og:url" content="http://localhost:4000/Workshops/session5_machine_learning.html">




  <meta property="og:image" content="http://localhost:4000/assets/images/margaret-weir-GZyjbLNOaFg-unsplash_dark.jpg">



  <meta name="twitter:site" content="@isugif">
  <meta name="twitter:title" content="Machine Learning">
  <meta name="twitter:description" content="Tutorial on Informatics for Geospatial Information">
  <meta name="twitter:url" content="http://localhost:4000/Workshops/session5_machine_learning.html">

  
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:image" content="http://localhost:4000/assets/images/margaret-weir-GZyjbLNOaFg-unsplash_dark.jpg">
  

  
    <meta name="twitter:creator" content="@someone">
  







  

  


<link rel="canonical" href="http://localhost:4000/Workshops/session5_machine_learning.html">







  <script type="application/ld+json">
    {
      "@context": "http://schema.org",
      "@type": "Person",
      "name": "",
      "url": "http://localhost:4000",
      "sameAs": null
    }
  </script>







<!-- end _includes/seo.html -->


<link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Geospatial Workbook Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">

<!--[if lte IE 9]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->


    <!-- start custom head snippets -->

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-E6BZVYF8ZY"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-E6BZVYF8ZY');
</script>

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single">

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    <div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <a class="site-title" href="/">Geospatial Workbook</a>
        <ul class="visible-links">
          
            
            <li class="masthead__menu-item">
              <a href="http://localhost:4000/about.html" >About</a>
            </li>
          
            
            <li class="masthead__menu-item">
              <a href="http://localhost:4000/list.html" >Index</a>
            </li>
          
            
            <li class="masthead__menu-item">
              <a href="http://localhost:4000/glossary.html" >Glossary</a>
            </li>
          
            
            <li class="masthead__menu-item">
              <a href="http://localhost:4000/people.html" >People</a>
            </li>
          
            
            <li class="masthead__menu-item">
              <a href="http://localhost:4000/contributing.html" >Contribute</a>
            </li>
          
        </ul>
        
        <button class="search__toggle" type="button">
          <svg class="icon" width="16" height="16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 15.99 16">
            <path d="M15.5,13.12L13.19,10.8a1.69,1.69,0,0,0-1.28-.55l-0.06-.06A6.5,6.5,0,0,0,5.77,0,6.5,6.5,0,0,0,2.46,11.59a6.47,6.47,0,0,0,7.74.26l0.05,0.05a1.65,1.65,0,0,0,.5,1.24l2.38,2.38A1.68,1.68,0,0,0,15.5,13.12ZM6.4,2A4.41,4.41,0,1,1,2,6.4,4.43,4.43,0,0,1,6.4,2Z" transform="translate(-.01)"></path>
          </svg>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle Menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      
  











<div class="page__hero--overlay"
  style="background-color: 444444; background-image: url('/assets/images/margaret-weir-GZyjbLNOaFg-unsplash_dark.jpg');"
>
  
    <div class="wrapper">
      <h1 id="page-title" class="page__title" itemprop="headline">
        
          Machine Learning

        
      </h1>
      
      
      
    </div>
  
  
</div>





<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="http://schema.org/Person">

  
    <div class="author__avatar">
      

      
        <img src="/assets/images/people/KerrieGeil.png" alt="Kerrie Geil" itemprop="image">
      
    </div>
  

  <div class="author__content">
    
      <h3 class="author__name" itemprop="name">Kerrie Geil</h3>
    
    
      <p class="author__bio" itemprop="description">
        Kerrie is an ARS SCINet postdoc in the research group of Dr. Deb Peters in Las Cruces, NM. Her M.S. and Ph.D. degrees are in Atmospheric Sciences and her research background is in climate modeling.
      </p>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      

      

      
        <li>
          <a href="mailto:mailto:someone@iastate.edu">
            <meta itemprop="email" content="mailto:someone@iastate.edu" />
            <i class="fas fa-fw fa-envelope-square" aria-hidden="true"></i> Email
          </a>
        </li>
      

      

      
        <li>
          <a href="https://twitter.com/someone" itemprop="sameAs">
            <i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter
          </a>
        </li>
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

<!-- Create a 2nd author for tutorials -->



<div itemscope itemtype="http://schema.org/Person">

  

  <div class="author__content">
    
      <h3 class="author__name" itemprop="name"></h3>
    
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
  </div>


  <article class="page" itemscope itemtype="http://schema.org/CreativeWork">
    <meta itemprop="headline" content="Machine Learning">
    
    
    

    <div class="page__inner-wrap">
      

      <section class="page__content" itemprop="text">
        
        <h1 id="distributed-machine-learning-pipeline-ndvi--soil--weather-dynamics">Distributed Machine Learning Pipeline: NDVI ~ Soil + Weather Dynamics</h1>
<p>By Kerrie Geil, USDA-ARS
August 2020
 —</p>

<p>This tutorial is also provided as a python notebook, which can be fetched by right-clicking, and downloading the linked file.</p>

<ul>
  <li><a href="https://raw.githubusercontent.com/kerriegeil/SCINET-GEOSPATIAL-RESEARCH-WG/master/tutorials/session5_machine_learning.ipynb">session5_machine_learning.ipynb</a></li>
</ul>

<p>Fetching the python notebook via <code class="language-plaintext highlighter-rouge">curl</code> or <code class="language-plaintext highlighter-rouge">wget</code> should also be possible.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>curl https://raw.githubusercontent.com/kerriegeil/SCINET-GEOSPATIAL-RESEARCH-WG/master/tutorials/session5_machine_learning.ipynb
</code></pre></div></div>

<p>This tutorial walks thru a machine learning pipeline. This example excludes the <em>Extract</em> component in the often referenced <em>ETL</em> (Extract, Transform, Learn) machine learning nomenclature. The overall goal of this analysis is to predict NDVI dynamics from soil and lagged precipitation, temperature, and vapor pressure deficit observations. The brief outline of the tutorial is:</p>

<ol>
  <li>Read and transform the NDVI, Soil, and Weather data.</li>
  <li>Merge the three datasets and add 26 weekly lags of precipitation, vpd, and temperature as features.</li>
  <li>Shuffle and split data into three groups:
    <ul>
      <li>3% for hyperparameter optimization (Group 1)</li>
      <li>97 % for final model</li>
    </ul>
    <ul>
      <li>77.6% (97% * 80%) for final model training (Group 2)</li>
      <li>19.4% (97% * 20%) for final model testing (validation) (Group 3)</li>
    </ul>
  </li>
  <li>Optimize the hyperparamters in an XGBoost model (Xtreme Gradient Boosting) using a small subset of the data.</li>
  <li>Using the “best fit” hyperparameters, train the model 77.6% of the data (Group 2).</li>
  <li>Validation with the test (hold-out) data (19.4% - Group 3)</li>
</ol>

<h2 id="table-of-contents">Table of Contents</h2>
<ol>
  <li><a href="#build-a-distributed-cluster">Build a Distributed Cluster</a></li>
  <li><a href="#preprocess-transfor-and-merge-the-data">Preprocess, Transform, and Merge the Data</a></li>
  <li><a href="#machine-learning-xgboost-model">Machine Learning: XGBoost Model</a></li>
  <li><a href="#interpreting-the-model">Interpreting the Model</a></li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">xarray</span> <span class="k">as</span> <span class="n">xr</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">dask_jobqueue</span> <span class="k">as</span> <span class="n">jq</span>
<span class="kn">import</span> <span class="nn">dask</span>
<span class="kn">from</span> <span class="nn">dask</span> <span class="kn">import</span> <span class="n">dataframe</span> <span class="k">as</span> <span class="n">ddf</span>
<span class="kn">from</span> <span class="nn">dask</span> <span class="kn">import</span> <span class="n">array</span> <span class="k">as</span> <span class="n">da</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">dask.distributed</span> <span class="kn">import</span> <span class="n">Client</span><span class="p">,</span> <span class="n">wait</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span>
<span class="kn">from</span> <span class="nn">tqdm.notebook</span> <span class="kn">import</span> <span class="n">tqdm</span>
</code></pre></div></div>

<h2 id="build-a-distributed-cluster">Build a Distributed Cluster<a class="anchor" id="build-a-distributed-cluster"></a></h2>

<p>We will use <a href="https://jobqueue.dask.org/en/latest/">dask-jobqueue</a> to launch and scale a cluster. For a more detailed example of how this works, please see the other tutorials in the SCINet Geospatial 2020 Workshop. For a quick review, the workflow for defining a cluster and scaling is:<br /></p>
<ol>
  <li>Dask-jobqueue submits jobs to Slurm with an sbatch script</li>
  <li>The sbatch scripts define the dask workers with the following info:
    * Partition to launch jobs/workers (<code class="language-plaintext highlighter-rouge">partition</code>)
    * X number of processes (i.e. dask workers) per sbatch script (<code class="language-plaintext highlighter-rouge">num_processes</code>).
    * Number of threads/cpus per dask worker (<code class="language-plaintext highlighter-rouge">num_threads_per_process</code>)
    * Memory allocated per sbatch scipt (<code class="language-plaintext highlighter-rouge">mem</code>), which is spread evenly between the dask workers.</li>
  <li>Scale the cluster to the total # of workers. Needs to be a multiple of num_processes.</li>
</ol>

<p>In this example, we are defining one process (dask worker) per sbatch script. Each process will have 40 cpus (an entire node). We then scale the cluster to 9 workers, which total 360 threads at 1.15TB of memory.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">partition</span><span class="o">=</span><span class="s">'short,brief-low'</span>
<span class="n">num_processes</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">num_threads_per_process</span> <span class="o">=</span> <span class="mi">40</span>
<span class="n">mem</span> <span class="o">=</span> <span class="mf">3.2</span><span class="o">*</span><span class="n">num_processes</span><span class="o">*</span><span class="n">num_threads_per_process</span>
<span class="n">n_cores_per_job</span> <span class="o">=</span> <span class="n">num_processes</span><span class="o">*</span><span class="n">num_threads_per_process</span>
<span class="n">container</span> <span class="o">=</span> <span class="s">'/lustre/project/geospatial_tutorials/wg_2020_ws/data_science_im_rs_vSCINetGeoWS_2020.sif'</span>
<span class="n">env</span> <span class="o">=</span> <span class="s">'py_geo'</span>
<span class="n">clust</span> <span class="o">=</span> <span class="n">jq</span><span class="p">.</span><span class="n">SLURMCluster</span><span class="p">(</span><span class="n">queue</span><span class="o">=</span><span class="n">partition</span><span class="p">,</span>
                        <span class="n">processes</span><span class="o">=</span><span class="n">num_processes</span><span class="p">,</span>
                        <span class="n">memory</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="n">mem</span><span class="p">)</span><span class="o">+</span><span class="s">'GB'</span><span class="p">,</span>
                        <span class="n">cores</span><span class="o">=</span><span class="n">n_cores_per_job</span><span class="p">,</span>
                        <span class="n">interface</span><span class="o">=</span><span class="s">'ib0'</span><span class="p">,</span>
                        <span class="n">local_directory</span><span class="o">=</span><span class="s">'$TMPDIR'</span><span class="p">,</span>
                        <span class="n">death_timeout</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
                        <span class="n">python</span><span class="o">=</span><span class="s">"singularity exec {} /opt/conda/envs/{}/bin/python"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">container</span><span class="p">,</span><span class="n">env</span><span class="p">),</span>
                        <span class="n">walltime</span><span class="o">=</span><span class="s">'01:30:00'</span><span class="p">,</span>
                        <span class="n">job_extra</span><span class="o">=</span><span class="p">[</span><span class="s">"--output=/dev/null"</span><span class="p">,</span><span class="s">"--error=/dev/null"</span><span class="p">])</span>
<span class="n">cl</span><span class="o">=</span><span class="n">Client</span><span class="p">(</span><span class="n">clust</span><span class="p">)</span>
<span class="n">cl</span>
<span class="k">print</span><span class="p">(</span><span class="s">'The Dask dashboard address is: /user/'</span><span class="o">+</span><span class="n">os</span><span class="p">.</span><span class="n">environ</span><span class="p">[</span><span class="s">'USER'</span><span class="p">]</span><span class="o">+</span><span class="s">'/proxy/'</span><span class="o">+</span><span class="n">cl</span><span class="p">.</span><span class="n">dashboard_link</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">':'</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="n">split</span><span class="p">(</span><span class="s">'/'</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="s">'/status'</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>View Cluster Dashboard</strong>
To view the cluster with the dask dashboard interaface click the dask icon on the left menu pane. Copy and paste the above dashboard address (in the form of /user/{User.Name}/proxy/{port#}/status) into the address bar. Then click on the “Workers”, “Progress”, “Task Stream”, and “CPU” to open those tabs. Drag and arrange in convineint layout on right-hand side of the screen. Note these panes should be mostly blank as we have yet to scale the cluster, which is the next step below.</p>

<p>Dask Icon:
<img src="https://avatars3.githubusercontent.com/u/17131925?s=400&amp;v=4" width="20" /></p>

<p><strong>Scale the Cluster</strong> to 9 workers (40 cpus per worker). This may take 5-20 seconds to complete.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#scale the cluster
</span><span class="n">n_workers</span><span class="o">=</span><span class="mi">9</span>
<span class="n">clust</span><span class="p">.</span><span class="n">scale</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">n_workers</span><span class="o">*</span><span class="n">num_processes</span><span class="p">)</span>
<span class="c1">#Wait for the cluster to load, show progress bar.
</span><span class="k">with</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">total</span><span class="o">=</span><span class="n">n_workers</span><span class="o">*</span><span class="n">num_processes</span><span class="p">)</span> <span class="k">as</span> <span class="n">pbar</span><span class="p">:</span>
    <span class="k">while</span> <span class="p">(((</span><span class="n">cl</span><span class="p">.</span><span class="n">status</span> <span class="o">==</span> <span class="s">"running"</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">cl</span><span class="p">.</span><span class="n">scheduler_info</span><span class="p">()[</span><span class="s">"workers"</span><span class="p">])</span> <span class="o">&lt;</span> <span class="n">n_workers</span><span class="o">*</span><span class="n">num_processes</span><span class="p">))):</span>
        <span class="n">pbar</span><span class="p">.</span><span class="n">update</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">cl</span><span class="p">.</span><span class="n">scheduler_info</span><span class="p">()[</span><span class="s">"workers"</span><span class="p">])</span><span class="o">-</span><span class="n">pbar</span><span class="p">.</span><span class="n">n</span><span class="p">)</span>
    <span class="n">pbar</span><span class="p">.</span><span class="n">update</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">cl</span><span class="p">.</span><span class="n">scheduler_info</span><span class="p">()[</span><span class="s">"workers"</span><span class="p">])</span><span class="o">-</span><span class="n">pbar</span><span class="p">.</span><span class="n">n</span><span class="p">)</span>
<span class="n">cl</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#Lets see the workers are running in SLURM
</span><span class="n">me</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">environ</span><span class="p">[</span><span class="s">'USER'</span><span class="p">]</span>
<span class="err">!</span><span class="n">squeue</span> <span class="o">-</span><span class="n">u</span> <span class="err">$</span><span class="n">me</span>
</code></pre></div></div>

<h2 id="preprocess-transform-and-merge-the-data">Preprocess, Transform, and Merge the Data<a class="anchor" id="preprocess-transfor-and-merge-the-data"></a></h2>

<h4 id="harmonized-landsat-sentinel-data">Harmonized Landsat Sentinel Data</h4>

<p>Link to data repository: https://hls.gsfc.nasa.gov/</p>

<p><strong>Workflow:</strong></p>
<ol>
  <li>Data is stored in the Zarr format with three dimensions (x,y,time).</li>
  <li>Read with xarray.</li>
  <li>Divide the data into chunks. Here we have chunked the data by: x=20 pixels, y=20 pixels, date=Entire Dataset</li>
  <li>Subset the data to only included “growing season” months.</li>
  <li>Convert the xarray object to a 2-Dimensional dataframe.</li>
</ol>

<p>Notice that the data is not read to memory. The only information stored is the “task graph” and metadata about the final results.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#Read the data with Xarray and rechunk
</span><span class="n">ndvi</span> <span class="o">=</span> <span class="n">xr</span><span class="p">.</span><span class="n">open_zarr</span><span class="p">(</span><span class="s">'/lustre/project/geospatial_tutorials/wg_2020_ws/data/cper_hls_ndvi.zarr/'</span><span class="p">).</span><span class="n">chunk</span><span class="p">({</span><span class="s">'x'</span><span class="p">:</span><span class="mi">20</span><span class="p">,</span><span class="s">'y'</span><span class="p">:</span><span class="mi">20</span><span class="p">,</span><span class="s">'date'</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">})</span>
<span class="n">ndvi</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#Select relevant months and then convert to a dataframe
</span><span class="n">ndvi_df</span> <span class="o">=</span> <span class="n">ndvi</span><span class="p">.</span><span class="n">sel</span><span class="p">(</span><span class="n">date</span><span class="o">=</span><span class="n">ndvi</span><span class="p">[</span><span class="s">'date.month'</span><span class="p">].</span><span class="n">isin</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">9</span><span class="p">])).</span><span class="n">to_dask_dataframe</span><span class="p">()</span>
<span class="c1">#Only include reasonable values (.1 &lt; NDVI &lt; 1.0) in the analysis
</span><span class="n">ndvi_df</span> <span class="o">=</span> <span class="n">ndvi_df</span><span class="p">[(</span><span class="n">ndvi_df</span><span class="p">.</span><span class="n">ndvi</span><span class="o">&gt;</span><span class="p">.</span><span class="mi">1</span><span class="p">)</span><span class="o">&amp;</span><span class="p">(</span><span class="n">ndvi_df</span><span class="p">.</span><span class="n">ndvi</span><span class="o">&lt;</span><span class="mf">1.</span><span class="p">)]</span>
<span class="k">print</span><span class="p">(</span><span class="s">'There are '</span><span class="o">+</span><span class="sa">f</span><span class="s">'</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">ndvi_df</span><span class="p">):,</span><span class="si">}</span><span class="s">'</span><span class="o">+</span><span class="s">' NDVI observations.'</span><span class="p">)</span>
<span class="n">ndvi_df</span>
</code></pre></div></div>

<h4 id="polaris-soil-hydraulic-data">Polaris Soil Hydraulic Data</h4>

<p>Paper Describing the Data: https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2018WR022797<br />
Data Repository Source:  http://hydrology.cee.duke.edu/POLARIS/PROPERTIES/v1.0/</p>

<p><strong>Workflow:</strong></p>
<ol>
  <li>Data is stored in the Zarr format with two dimensions (x,y) and includes 13 variables at 6 depths (78 total). Read with xarray.</li>
  <li>Interpolate the data to the same grid as the HLS NDVI data.</li>
  <li>Convert the xarray object to a 2-Dimensional Pandas dataframe.</li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">soil</span> <span class="o">=</span> <span class="n">xr</span><span class="p">.</span><span class="n">open_zarr</span><span class="p">(</span><span class="s">'/lustre/project/geospatial_tutorials/wg_2020_ws/data/polaris_soils.zarr/'</span><span class="p">)</span>
<span class="c1">#Interpolate to the HLS NDVI grid
</span><span class="n">soil_df</span> <span class="o">=</span> <span class="n">soil</span><span class="p">.</span><span class="n">interp</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">ndvi</span><span class="p">.</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="n">ndvi</span><span class="p">.</span><span class="n">y</span><span class="p">,</span><span class="n">method</span><span class="o">=</span><span class="s">'linear'</span><span class="p">).</span><span class="n">squeeze</span><span class="p">().</span><span class="n">to_dataframe</span><span class="p">().</span><span class="n">reset_index</span><span class="p">()</span>
<span class="n">soil_df</span>
</code></pre></div></div>

<h4 id="prism-precipitation-tempature-and-vapor-pressure-deficit-data">PRISM Precipitation, Tempature, and Vapor Pressure Deficit Data</h4>

<p>PRISM Data in a CSV file. Note this data was queried at a single point at the center of CPER.</p>

<p><strong>Workflow:</strong></p>
<ol>
  <li>Data is stored in the csv format and includes 7 variables. Read with Pandas using:
    * Skip the 1st 10 rows (PRISM metadata)
    * Convert the time column from a generic object to a date-time object.</li>
  <li>Rename the “Date” to “date” to match HLS NDVI data.</li>
  <li>Set the “date” column as the index.</li>
  <li>Sort the data into descending.</li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_env</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'/lustre/project/geospatial_tutorials/wg_2020_ws/data/PRISM_ppt_tmin_tmean_tmax_tdmean_vpdmin_vpdmax_provisional_4km_20120101_20200101_40.8269_-104.7154.csv'</span><span class="p">,</span>
                      <span class="n">skiprows</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                      <span class="n">infer_datetime_format</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                      <span class="n">parse_dates</span> <span class="o">=</span> <span class="p">[</span><span class="s">'Date'</span><span class="p">]).</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s">'Date'</span><span class="p">:</span><span class="s">'date'</span><span class="p">}).</span><span class="n">set_index</span><span class="p">(</span><span class="s">'date'</span><span class="p">).</span><span class="n">sort_index</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">df_env</span>
</code></pre></div></div>

<h4 id="transform-function-to-merge-ndvi-soil-and-prism-data">Transform Function to Merge NDVI, Soil, and PRISM data.</h4>

<p>Here we develop a class to merge the three dataset. Note the most import code is in the <code class="language-plaintext highlighter-rouge">def transform</code> function.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#Costum transformer in the scikit-learn API syntax
</span><span class="k">class</span> <span class="nc">merge_dsets</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span><span class="n">TransformerMixin</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">df_soil</span><span class="p">,</span> <span class="n">df_env</span><span class="p">,</span><span class="n">lag</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">soil</span> <span class="o">=</span> <span class="n">df_soil</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">env</span> <span class="o">=</span> <span class="n">df_env</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">lag</span> <span class="o">=</span> <span class="n">lag</span>
        <span class="c1">#self.lag_interv = lag_interval
</span>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span>
    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">merge</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">soil</span><span class="p">,</span> <span class="n">on</span> <span class="o">=</span><span class="p">[</span><span class="s">'x'</span><span class="p">,</span><span class="s">'y'</span><span class="p">])</span>
        <span class="n">df_env_m</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">d</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">date</span><span class="p">.</span><span class="n">unique</span><span class="p">()):</span>
            <span class="n">df_env_temp</span> <span class="o">=</span> <span class="n">df_env</span><span class="p">[</span><span class="n">df_env</span><span class="p">.</span><span class="n">index</span><span class="o">&lt;</span><span class="n">d</span><span class="o">+</span><span class="n">pd</span><span class="p">.</span><span class="n">Timedelta</span><span class="p">(</span><span class="s">'1days'</span><span class="p">)].</span><span class="n">resample</span><span class="p">(</span><span class="s">'1W-'</span><span class="o">+</span><span class="n">d</span><span class="p">.</span><span class="n">day_name</span><span class="p">()[</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">].</span><span class="n">upper</span><span class="p">(),</span>
                                                                                <span class="n">label</span><span class="o">=</span><span class="s">'right'</span><span class="p">).</span><span class="n">agg</span><span class="p">({</span><span class="s">'ppt (mm)'</span><span class="p">:</span><span class="s">'sum'</span><span class="p">,</span>
                                                                                                    <span class="s">'tmean (degrees C)'</span><span class="p">:</span><span class="s">'mean'</span><span class="p">,</span>
                                                                                                    <span class="s">'vpdmin (hPa)'</span><span class="p">:</span><span class="s">'mean'</span><span class="p">,</span>
                                                                                                    <span class="s">'vpdmax (hPa)'</span><span class="p">:</span><span class="s">'mean'</span><span class="p">}).</span><span class="n">sort_index</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">).</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="bp">self</span><span class="p">.</span><span class="n">lag</span><span class="p">].</span><span class="n">reset_index</span><span class="p">().</span><span class="n">reset_index</span><span class="p">().</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s">'index'</span><span class="p">:</span><span class="s">'week'</span><span class="p">})</span>
            <span class="n">df_env_temp</span> <span class="o">=</span> <span class="n">df_env_temp</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="s">'date'</span><span class="p">).</span><span class="n">melt</span><span class="p">(</span><span class="n">id_vars</span><span class="o">=</span><span class="s">'week'</span><span class="p">)</span>
            <span class="n">df_env_temp</span><span class="p">[</span><span class="s">'col'</span><span class="p">]</span><span class="o">=</span><span class="s">'week'</span><span class="o">+</span><span class="n">df_env_temp</span><span class="p">.</span><span class="n">week</span><span class="p">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span><span class="o">+</span><span class="s">'_'</span><span class="o">+</span><span class="n">df_env_temp</span><span class="p">.</span><span class="n">variable</span><span class="p">.</span><span class="nb">str</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">' '</span><span class="p">,</span><span class="n">expand</span><span class="o">=</span><span class="bp">True</span><span class="p">).</span><span class="n">values</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">df_env_temp</span> <span class="o">=</span> <span class="n">df_env_temp</span><span class="p">.</span><span class="n">set_index</span><span class="p">(</span><span class="s">'col'</span><span class="p">).</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">'week'</span><span class="p">,</span><span class="s">'variable'</span><span class="p">]).</span><span class="n">T</span>
            <span class="n">df_env_temp</span><span class="p">[</span><span class="s">'date'</span><span class="p">]</span><span class="o">=</span><span class="n">d</span>
            <span class="n">df_env_temp</span> <span class="o">=</span> <span class="n">df_env_temp</span><span class="p">.</span><span class="n">set_index</span><span class="p">(</span><span class="s">'date'</span><span class="p">,</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            <span class="n">df_env_m</span> <span class="o">=</span> <span class="n">df_env_m</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">df_env_temp</span><span class="p">)</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">merge</span><span class="p">(</span><span class="n">df_env_m</span><span class="p">,</span><span class="n">left_on</span><span class="o">=</span><span class="s">'date'</span><span class="p">,</span><span class="n">right_index</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">df</span><span class="p">[</span><span class="s">'DOY'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">date</span><span class="p">.</span><span class="n">dt</span><span class="p">.</span><span class="n">dayofyear</span>
        <span class="k">return</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">'date'</span><span class="p">,</span><span class="s">'x'</span><span class="p">,</span><span class="s">'y'</span><span class="p">,</span><span class="s">'ndvi'</span><span class="p">]),</span><span class="n">df</span><span class="p">[[</span><span class="s">'ndvi'</span><span class="p">]])</span><span class="c1">#.to_dask_array(lengths=True))
</span></code></pre></div></div>

<h2 id="machine-learning-xgboost-model">Machine Learning: XGBoost Model<a class="anchor" id="machine-learning-xgboost-model"></a></h2>
<p>The “<em>learn</em>” portion in the ETL pipeline.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">import</span> <span class="nn">xgboost</span> <span class="k">as</span> <span class="n">xgb</span>
<span class="c1">#from dask_ml.xgboost import XGBRegressor as dask_XGBRegressor
</span><span class="kn">from</span> <span class="nn">dask_ml.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">r2_score</span>
<span class="kn">from</span> <span class="nn">dask_ml.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span> <span class="k">as</span> <span class="n">sk_GridSearchCV</span>
<span class="kn">import</span> <span class="nn">joblib</span>
</code></pre></div></div>

<h3 id="hyperparameter-optimization">Hyperparameter Optimization</h3>

<p>Shuffle and subset data to a <em>managable size</em> (e.g. will fit in memory when running 360 simaltaneous models). We will use a grid-search, combined with 3-fold cross validation, approach to optimize the relevant hyperparameters (see table below).</p>

<table>
  <thead>
    <tr>
      <th>Hyperparameter</th>
      <th>Grid</th>
      <th>n</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>n_estimators</td>
      <td>[150, 250, 300, 350]</td>
      <td>4</td>
    </tr>
    <tr>
      <td>learning_rate</td>
      <td>[0.05, 0.1, 0.2, 0.3]</td>
      <td>4</td>
    </tr>
    <tr>
      <td>max_depth</td>
      <td>[5, 7, 9, 11]</td>
      <td>4</td>
    </tr>
    <tr>
      <td>colsample_bytree</td>
      <td>[.1, .2, .3]</td>
      <td>3</td>
    </tr>
    <tr>
      <td>gamma</td>
      <td>[.05, .1, .2]</td>
      <td>3</td>
    </tr>
  </tbody>
</table>

<p>A total of 1728 models (4 * 4 * 4 * 3 * 3 * 3) will be fit. The hyperparameters assocated with the best scoring model (highest R2) will be used to train the remianing data.</p>

<p>This search can take ~1-2 hour using 360 cores. To run the hyperparameter gridsearch cross validation, set the <code class="language-plaintext highlighter-rouge">optimize_hyperparameter</code> variable to <code class="language-plaintext highlighter-rouge">True</code> (see two cells below). If you leave as <code class="language-plaintext highlighter-rouge">False</code>, we will skip the hyperparameter calculatoins, and just use the hyperparameter values previously calculated.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_train_hyp</span><span class="p">,</span> <span class="n">X</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">ndvi_df</span><span class="p">,</span>
                                  <span class="n">test_size</span><span class="o">=</span><span class="mf">0.97</span><span class="p">,</span>
                                  <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                                  <span class="n">random_state</span><span class="o">=</span><span class="mi">34</span><span class="p">)</span>
<span class="n">X_train_hyp</span><span class="p">,</span><span class="n">Y_train_hyp</span> <span class="o">=</span> <span class="n">dask</span><span class="p">.</span><span class="n">compute</span><span class="p">(</span><span class="o">*</span><span class="n">merge_dsets</span><span class="p">(</span><span class="n">df_soil</span><span class="o">=</span><span class="n">soil_df</span><span class="p">,</span>
                                      <span class="n">df_env</span><span class="o">=</span><span class="n">df_env</span><span class="p">,</span>
                                      <span class="n">lag</span><span class="o">=</span><span class="mi">26</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train_hyp</span><span class="p">))</span>
<span class="n">X_train_hyp</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Set to True if you want to run the Gridsearch. This can take &gt;1.5 hrs. Therefore, 
# if set to false, the results (best hyperparameters) hardcoded from a previous run 
# of the model
</span><span class="n">optimize_hyperparameters</span> <span class="o">=</span> <span class="bp">False</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">if</span> <span class="n">optimize_hyperparameters</span><span class="p">:</span>
    <span class="c1">#Define the grid - space
</span>    <span class="n">param_dist</span> <span class="o">=</span> <span class="p">{</span><span class="s">'n_estimators'</span><span class="p">:</span> <span class="p">[</span><span class="mi">150</span><span class="p">,</span><span class="mi">250</span><span class="p">,</span><span class="mi">300</span><span class="p">,</span><span class="mi">350</span><span class="p">],</span>
        <span class="s">'learning_rate'</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">],</span>
        <span class="s">'max_depth'</span><span class="p">:</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">11</span><span class="p">],</span>
        <span class="s">'colsample_bytree'</span><span class="p">:</span> <span class="p">[.</span><span class="mi">1</span><span class="p">,</span> <span class="p">.</span><span class="mi">2</span><span class="p">,</span> <span class="p">.</span><span class="mi">3</span><span class="p">],</span>
        <span class="s">'gamma'</span><span class="p">:</span> <span class="p">[.</span><span class="mi">05</span><span class="p">,</span> <span class="p">.</span><span class="mi">1</span><span class="p">,</span> <span class="p">.</span><span class="mi">2</span><span class="p">]}</span>
    <span class="c1">#Define the XGBoost model
</span>    <span class="n">reg</span> <span class="o">=</span> <span class="n">xgb</span><span class="p">.</span><span class="n">XGBRegressor</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">verbosity</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
    <span class="c1">#Setup the GridsearchCV function
</span>    <span class="n">gs</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">reg</span><span class="p">,</span><span class="n">param_dist</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span><span class="n">scheduler</span><span class="o">=</span><span class="n">cl</span><span class="p">,</span><span class="n">refit</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span><span class="n">cache_cv</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    <span class="c1">#Fit all the models
</span>    <span class="n">gs</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_hyp</span><span class="p">.</span><span class="n">values</span><span class="p">,</span><span class="n">Y_train_hyp</span><span class="p">.</span><span class="n">values</span><span class="p">)</span>
    <span class="c1">#Get the best fitting parameters
</span>    <span class="n">df_params</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">gs</span><span class="p">.</span><span class="n">cv_results_</span><span class="p">)</span>
    <span class="n">best_params</span> <span class="o">=</span> <span class="n">df_params</span><span class="p">[</span><span class="n">df_params</span><span class="p">.</span><span class="n">mean_test_score</span><span class="o">==</span><span class="n">df_params</span><span class="p">.</span><span class="n">mean_test_score</span><span class="p">.</span><span class="nb">max</span><span class="p">()]</span>
    <span class="n">best_params</span> <span class="o">=</span> <span class="n">best_params</span><span class="p">.</span><span class="n">params</span><span class="p">.</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">print</span><span class="p">(</span><span class="n">best_params</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="c1">#Best fit parameters from previous run
</span>    <span class="n">best_params</span> <span class="o">=</span> <span class="p">{</span><span class="s">'colsample_bytree'</span><span class="p">:</span> <span class="mf">0.2</span><span class="p">,</span>
                   <span class="s">'gamma'</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span>
                   <span class="s">'learning_rate'</span><span class="p">:</span> <span class="mf">0.05</span><span class="p">,</span>
                   <span class="s">'max_depth'</span><span class="p">:</span> <span class="mi">7</span><span class="p">,</span>
                   <span class="s">'n_estimators'</span><span class="p">:</span> <span class="mi">350</span><span class="p">}</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'Using the previously calculated parameters, which are:'</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">best_params</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="distributed-xgboost-model">Distributed XGBoost Model</h3>

<ul>
  <li>Shuffle and split data into “training” (80%) and “testing” (20%). Leave as dask dataframes (data needs to be distributed across all workers), so we will call <code class="language-plaintext highlighter-rouge">dask.persist</code> to trigger the calculation (rather than dask.compute).</li>
  <li>Train XGBoost model using the training data.</li>
  <li>Model Validation / Accuracy (r2) with “testing” data</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Split the data
</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span>
                                   <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
                                   <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="c1">#Merge the weather/soil data and persist the data across the cluster
</span><span class="p">[</span><span class="n">X_train</span><span class="p">,</span><span class="n">Y_train</span><span class="p">],[</span><span class="n">X_test</span><span class="p">,</span><span class="n">Y_test</span><span class="p">]</span> <span class="o">=</span> <span class="n">dask</span><span class="p">.</span><span class="n">persist</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">merge_dsets</span><span class="p">(</span><span class="n">df_soil</span><span class="o">=</span><span class="n">soil_df</span><span class="p">,</span><span class="n">df_env</span><span class="o">=</span><span class="n">df_env</span><span class="p">,</span><span class="n">lag</span><span class="o">=</span><span class="mi">26</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">),</span>
                                               <span class="n">merge_dsets</span><span class="p">(</span><span class="n">df_soil</span><span class="o">=</span><span class="n">soil_df</span><span class="p">,</span><span class="n">df_env</span><span class="o">=</span><span class="n">df_env</span><span class="p">,</span><span class="n">lag</span><span class="o">=</span><span class="mi">26</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)])</span>
<span class="n">wait</span><span class="p">([</span><span class="n">X_train</span><span class="p">,</span><span class="n">X_test</span><span class="p">,</span><span class="n">Y_train</span><span class="p">,</span><span class="n">Y_test</span><span class="p">])</span>
<span class="n">X_train</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#Setup the Distributed XGBoost model and train it on the "training" data
</span><span class="n">dtrain</span> <span class="o">=</span> <span class="n">xgb</span><span class="p">.</span><span class="n">dask</span><span class="p">.</span><span class="n">DaskDMatrix</span><span class="p">(</span><span class="n">cl</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>
<span class="n">reg_b</span> <span class="o">=</span> <span class="n">xgb</span><span class="p">.</span><span class="n">dask</span><span class="p">.</span><span class="n">train</span><span class="p">(</span><span class="n">cl</span><span class="p">,</span>
                       <span class="n">best_params</span><span class="p">,</span>
                       <span class="n">dtrain</span><span class="p">,</span>
                       <span class="n">num_boost_round</span><span class="o">=</span><span class="mi">125</span><span class="p">,</span>
                       <span class="n">evals</span><span class="o">=</span><span class="p">[(</span><span class="n">dtrain</span><span class="p">,</span> <span class="s">'train'</span><span class="p">)])</span>
<span class="k">print</span><span class="p">(</span><span class="n">reg_b</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#Get the R2 results for the testing data
</span><span class="n">dtest</span> <span class="o">=</span> <span class="n">xgb</span><span class="p">.</span><span class="n">dask</span><span class="p">.</span><span class="n">DaskDMatrix</span><span class="p">(</span><span class="n">cl</span><span class="p">,</span> <span class="n">X_test</span><span class="p">)</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">xgb</span><span class="p">.</span><span class="n">dask</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">cl</span><span class="p">,</span> <span class="n">reg_b</span><span class="p">[</span><span class="s">'booster'</span><span class="p">],</span> <span class="n">dtest</span><span class="p">)</span>
<span class="n">reg_r2</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">Y_test</span><span class="p">.</span><span class="n">ndvi</span><span class="p">.</span><span class="n">compute</span><span class="p">().</span><span class="n">values</span><span class="p">,</span><span class="n">pred</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"The overall R2 is: "</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">reg_r2</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#Big Data Plotting Libraries
</span><span class="kn">import</span> <span class="nn">datashader</span> <span class="k">as</span> <span class="n">ds</span>
<span class="kn">import</span> <span class="nn">holoviews</span> <span class="k">as</span> <span class="n">hv</span>
<span class="kn">from</span> <span class="nn">holoviews.operation.datashader</span> <span class="kn">import</span> <span class="n">datashade</span><span class="p">,</span> <span class="n">shade</span><span class="p">,</span> <span class="n">dynspread</span><span class="p">,</span> <span class="n">rasterize</span>
<span class="n">hv</span><span class="p">.</span><span class="n">extension</span><span class="p">(</span><span class="s">'bokeh'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#Plot the results
</span><span class="n">Y_plotting</span> <span class="o">=</span> <span class="n">Y_test</span><span class="p">.</span><span class="n">compute</span><span class="p">()</span>
<span class="n">Y_plotting</span><span class="p">[</span><span class="s">'pred'</span><span class="p">]</span><span class="o">=</span><span class="n">pred</span><span class="p">.</span><span class="n">compute</span><span class="p">()</span>
<span class="n">Y_plotting</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#To plot all the points, we need to rasterize the data (aka a 2d histogram)
</span><span class="n">pts_res</span> <span class="o">=</span> <span class="n">hv</span><span class="p">.</span><span class="n">Points</span><span class="p">(</span><span class="n">Y_plotting</span><span class="p">.</span><span class="n">values</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s">""</span><span class="p">)</span>
<span class="n">rasterize</span><span class="p">(</span><span class="n">pts_res</span><span class="p">).</span><span class="n">redim</span><span class="p">.</span><span class="nb">range</span><span class="p">(</span><span class="n">Count</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">2000</span><span class="p">)).</span><span class="n">opts</span><span class="p">(</span><span class="n">cmap</span><span class="o">=</span><span class="s">'viridis'</span><span class="p">,</span>
                                                      <span class="n">tools</span><span class="o">=</span><span class="p">[</span><span class="s">'hover'</span><span class="p">],</span>
                                                      <span class="n">xlim</span><span class="o">=</span><span class="p">(</span><span class="mf">0.15</span><span class="p">,.</span><span class="mi">6</span><span class="p">),</span>
                                                      <span class="n">ylim</span><span class="o">=</span><span class="p">(</span><span class="mf">0.15</span><span class="p">,.</span><span class="mi">6</span><span class="p">),</span>
                                                      <span class="n">clipping_colors</span><span class="o">=</span><span class="p">{</span><span class="s">'min'</span><span class="p">:</span> <span class="s">'transparent'</span><span class="p">},</span>
                                                      <span class="n">xlabel</span><span class="o">=</span><span class="s">'HLS NDVI'</span><span class="p">,</span>
                                                      <span class="n">ylabel</span><span class="o">=</span><span class="s">'Predicted NDVI'</span><span class="p">,</span>
                                                      <span class="n">logz</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="interpreting-the-model">Interpreting the Model<a class="anchor" id="interpreting-the-model"></a></h2>

<p><strong>Use the <a href="https://github.com/slundberg/shap">SHAP (SHapley Additive exPlanations) package</a></strong> to interpret the model results and better understand the features “driving” ndvi dynamics.</p>

<p>SHAP Papers: https://www.nature.com/articles/s42256-019-0138-9 and http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions</p>

<p>SHAP Blog: https://towardsdatascience.com/interpretable-machine-learning-with-xgboost-9ec80d148d27</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#Standard approaches can render different results
#Show the top 20 most import features as defined by the XGBoost model
</span><span class="n">xgb</span><span class="p">.</span><span class="n">plot_importance</span><span class="p">(</span><span class="n">reg_b</span><span class="p">[</span><span class="s">'booster'</span><span class="p">],</span><span class="n">max_num_features</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span><span class="n">importance_type</span><span class="o">=</span><span class="s">'weight'</span><span class="p">)</span>
<span class="n">xgb</span><span class="p">.</span><span class="n">plot_importance</span><span class="p">(</span><span class="n">reg_b</span><span class="p">[</span><span class="s">'booster'</span><span class="p">],</span><span class="n">max_num_features</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span><span class="n">importance_type</span><span class="o">=</span><span class="s">'gain'</span><span class="p">)</span>
<span class="n">xgb</span><span class="p">.</span><span class="n">plot_importance</span><span class="p">(</span><span class="n">reg_b</span><span class="p">[</span><span class="s">'booster'</span><span class="p">],</span><span class="n">max_num_features</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span><span class="n">importance_type</span><span class="o">=</span><span class="s">'cover'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#Import the SHAP libraries
</span><span class="kn">import</span> <span class="nn">shap</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="n">shap</span><span class="p">.</span><span class="n">initjs</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#Split data into better manageable slices
</span><span class="n">X_shap</span><span class="p">,</span> <span class="n">_</span><span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span><span class="n">test_size</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span><span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>Apply SHAP Model:</strong> Below we split the data by month, and examine the effect of the features on the model (by month).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#Day of Year for each month
</span><span class="n">months</span> <span class="o">=</span> <span class="p">{</span><span class="s">'May'</span><span class="p">:[</span><span class="mi">121</span><span class="p">,</span><span class="mi">152</span><span class="p">],</span>
          <span class="s">'June'</span><span class="p">:[</span><span class="mi">153</span><span class="p">,</span><span class="mi">182</span><span class="p">],</span>
          <span class="s">'July'</span><span class="p">:[</span><span class="mi">183</span><span class="p">,</span><span class="mi">2013</span><span class="p">],</span>
          <span class="s">'August'</span><span class="p">:[</span><span class="mi">214</span><span class="p">,</span><span class="mi">244</span><span class="p">],</span>
          <span class="s">'September'</span><span class="p">:[</span><span class="mi">245</span><span class="p">,</span><span class="mi">274</span><span class="p">]}</span>

<span class="c1">#Function for calculating SHAP values. We will map this function across the data on the cluster
</span><span class="k">def</span> <span class="nf">calc_shap_vals</span><span class="p">(</span><span class="n">block</span><span class="p">,</span><span class="n">explainer</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">block</span><span class="p">)</span><span class="o">&gt;</span><span class="mi">0</span><span class="p">:</span>
        <span class="n">block_vals</span> <span class="o">=</span> <span class="n">explainer</span><span class="p">.</span><span class="n">shap_values</span><span class="p">(</span><span class="n">block</span><span class="p">)</span>
        <span class="k">return</span><span class="p">(</span><span class="n">block_vals</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span><span class="mi">184</span><span class="p">)))</span>

<span class="c1">#Loop over each month and create plot
</span><span class="n">explainer</span> <span class="o">=</span> <span class="n">shap</span><span class="p">.</span><span class="n">TreeExplainer</span><span class="p">(</span><span class="n">reg_b</span><span class="p">[</span><span class="s">'booster'</span><span class="p">])</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">months</span><span class="p">.</span><span class="n">keys</span><span class="p">():</span>
    <span class="k">print</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">months</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">end</span> <span class="o">=</span> <span class="n">months</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
    <span class="c1">#Select only the data in the month
</span>    <span class="n">X_shap1</span> <span class="o">=</span> <span class="n">X_shap</span><span class="p">[(</span><span class="n">X_shap</span><span class="p">.</span><span class="n">DOY</span><span class="o">&gt;=</span><span class="n">start</span><span class="p">)</span><span class="o">&amp;</span><span class="p">(</span><span class="n">X_shap</span><span class="p">.</span><span class="n">DOY</span><span class="o">&lt;=</span><span class="n">end</span><span class="p">)].</span><span class="n">repartition</span><span class="p">(</span><span class="n">npartitions</span><span class="o">=</span><span class="mi">9</span><span class="p">).</span><span class="n">persist</span><span class="p">()</span>
    <span class="n">wait</span><span class="p">(</span><span class="n">X_shap1</span><span class="p">)</span>
    <span class="c1">#Compute the SHAP values
</span>    <span class="n">shap_vals</span> <span class="o">=</span> <span class="n">X_shap1</span><span class="p">.</span><span class="n">to_dask_array</span><span class="p">(</span><span class="n">lengths</span><span class="o">=</span><span class="bp">True</span><span class="p">).</span><span class="n">map_blocks</span><span class="p">(</span><span class="n">calc_shap_vals</span><span class="p">,</span><span class="n">explainer</span><span class="o">=</span><span class="n">explainer</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="s">'float32'</span><span class="p">).</span><span class="n">compute</span><span class="p">()</span>
    <span class="c1">#Show the SHAP summary plots for each month
</span>    <span class="k">print</span><span class="p">(</span><span class="s">'Using an array of size:'</span> <span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">shap_vals</span><span class="p">.</span><span class="n">shape</span><span class="p">))</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
    <span class="n">shap</span><span class="p">.</span><span class="n">summary_plot</span><span class="p">(</span><span class="n">shap_vals</span><span class="p">,</span> <span class="n">X_shap1</span><span class="p">.</span><span class="n">compute</span><span class="p">(),</span><span class="n">max_display</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span><span class="n">title</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">shap_vals</span> <span class="o">=</span> <span class="n">X_shap</span><span class="p">.</span><span class="n">to_dask_array</span><span class="p">(</span><span class="n">lengths</span><span class="o">=</span><span class="bp">True</span><span class="p">).</span><span class="n">map_blocks</span><span class="p">(</span><span class="n">calc_shap_vals</span><span class="p">,</span><span class="n">explainer</span><span class="o">=</span><span class="n">explainer</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="s">'float32'</span><span class="p">).</span><span class="n">compute</span><span class="p">()</span>
<span class="n">shap_vals</span> <span class="o">=</span> <span class="n">shap_vals</span><span class="p">[</span><span class="o">~</span><span class="n">np</span><span class="p">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">shap_vals</span><span class="p">).</span><span class="nb">any</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)]</span>
<span class="n">shap</span><span class="p">.</span><span class="n">dependence_plot</span><span class="p">(</span><span class="s">"week0_tmean"</span><span class="p">,</span> <span class="n">shap_vals</span><span class="p">,</span> <span class="n">X_shap</span><span class="p">.</span><span class="n">compute</span><span class="p">(),</span><span class="n">interaction_index</span><span class="o">=</span><span class="s">'DOY'</span><span class="p">)</span>
<span class="n">shap</span><span class="p">.</span><span class="n">dependence_plot</span><span class="p">(</span><span class="s">"week0_ppt"</span><span class="p">,</span> <span class="n">shap_vals</span><span class="p">,</span> <span class="n">X_shap</span><span class="p">.</span><span class="n">compute</span><span class="p">(),</span><span class="n">interaction_index</span><span class="o">=</span><span class="s">'DOY'</span><span class="p">)</span>
<span class="n">shap</span><span class="p">.</span><span class="n">dependence_plot</span><span class="p">(</span><span class="s">"week4_vpdmax"</span><span class="p">,</span> <span class="n">shap_vals</span><span class="p">,</span> <span class="n">X_shap</span><span class="p">.</span><span class="n">compute</span><span class="p">(),</span><span class="n">interaction_index</span><span class="o">=</span><span class="s">'DOY'</span><span class="p">)</span>
</code></pre></div></div>

        
      </section>

      <footer class="page__meta">
        
        


        
      </footer>

      

      

    </div>

    
  </article>

  
  
</div>
    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><form onsubmit="return googleCustomSearchExecute();" id="cse-search-box-form-id">
    <input type="search" id="cse-search-input-box-id" aria-placeholder="Enter your search term..." class="search-input" tabindex="-1" placeholder="Enter your search term..." />
    </form>
    <div id="results" class="results">
        <gcse:searchresults-only></gcse:searchresults-only>
    </div></div>

      </div>
    
    
    <div class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->

        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    
    
      <li><a href="https://twitter.com/isugif"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
    
    
    
      <li><a href="https://github.com/https://github.com/isugenomics"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
    
    
    
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2024 Geospatial Workbook</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>
  <script src="https://use.fontawesome.com/releases/v5.0.13/js/all.js"></script>


<script>
  (function () {
    var cx = '009853197685285203469:nsvri1pa88d';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();

  function googleCustomSearchExecute() {
    var input = document.getElementById('cse-search-input-box-id');
    var element = google.search.cse.element.getElement('searchresults-only0');
    if (input.value == '') {
      element.clearAllResults();
    } else {
      element.execute(input.value);
    }
    return false;
  }

  
</script>




<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" defer
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>




  </body>
</html>
