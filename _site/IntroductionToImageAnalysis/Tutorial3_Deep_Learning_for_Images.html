<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.11.2 by Michael Rose
  Copyright 2013-2018 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE.txt
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Premeeting - Geospatial Workbook</title>
<meta name="description" content="Tutorial on Informatics for Geospatial Information">


  <meta name="author" content="Kerrie Geil">


<meta property="og:type" content="website">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Geospatial Workbook">
<meta property="og:title" content="Premeeting">
<meta property="og:url" content="http://localhost:4000/IntroductionToImageAnalysis/Tutorial3_Deep_Learning_for_Images.html">




  <meta property="og:image" content="http://localhost:4000/assets/images/margaret-weir-GZyjbLNOaFg-unsplash_dark.jpg">



  <meta name="twitter:site" content="@isugif">
  <meta name="twitter:title" content="Premeeting">
  <meta name="twitter:description" content="Tutorial on Informatics for Geospatial Information">
  <meta name="twitter:url" content="http://localhost:4000/IntroductionToImageAnalysis/Tutorial3_Deep_Learning_for_Images.html">

  
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:image" content="http://localhost:4000/assets/images/margaret-weir-GZyjbLNOaFg-unsplash_dark.jpg">
  

  
    <meta name="twitter:creator" content="@someone">
  







  

  


<link rel="canonical" href="http://localhost:4000/IntroductionToImageAnalysis/Tutorial3_Deep_Learning_for_Images.html">







  <script type="application/ld+json">
    {
      "@context": "http://schema.org",
      "@type": "Person",
      "name": "",
      "url": "http://localhost:4000",
      "sameAs": null
    }
  </script>







<!-- end _includes/seo.html -->


<link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Geospatial Workbook Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">

<!--[if lte IE 9]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->


    <!-- start custom head snippets -->

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-E6BZVYF8ZY"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-E6BZVYF8ZY');
</script>

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single">

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    <div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <a class="site-title" href="/">Geospatial Workbook</a>
        <ul class="visible-links">
          
            
            <li class="masthead__menu-item">
              <a href="http://localhost:4000/about.html" >About</a>
            </li>
          
            
            <li class="masthead__menu-item">
              <a href="http://localhost:4000/list.html" >Index</a>
            </li>
          
            
            <li class="masthead__menu-item">
              <a href="http://localhost:4000/glossary.html" >Glossary</a>
            </li>
          
            
            <li class="masthead__menu-item">
              <a href="http://localhost:4000/people.html" >People</a>
            </li>
          
            
            <li class="masthead__menu-item">
              <a href="http://localhost:4000/contributing.html" >Contribute</a>
            </li>
          
        </ul>
        
        <button class="search__toggle" type="button">
          <svg class="icon" width="16" height="16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 15.99 16">
            <path d="M15.5,13.12L13.19,10.8a1.69,1.69,0,0,0-1.28-.55l-0.06-.06A6.5,6.5,0,0,0,5.77,0,6.5,6.5,0,0,0,2.46,11.59a6.47,6.47,0,0,0,7.74.26l0.05,0.05a1.65,1.65,0,0,0,.5,1.24l2.38,2.38A1.68,1.68,0,0,0,15.5,13.12ZM6.4,2A4.41,4.41,0,1,1,2,6.4,4.43,4.43,0,0,1,6.4,2Z" transform="translate(-.01)"></path>
          </svg>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle Menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      
  











<div class="page__hero--overlay"
  style="background-color: 444444; background-image: url('/assets/images/margaret-weir-GZyjbLNOaFg-unsplash_dark.jpg');"
>
  
    <div class="wrapper">
      <h1 id="page-title" class="page__title" itemprop="headline">
        
          Premeeting

        
      </h1>
      
      
      
    </div>
  
  
</div>





<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="http://schema.org/Person">

  
    <div class="author__avatar">
      

      
        <img src="/assets/images/people/KerrieGeil.png" alt="Kerrie Geil" itemprop="image">
      
    </div>
  

  <div class="author__content">
    
      <h3 class="author__name" itemprop="name">Kerrie Geil</h3>
    
    
      <p class="author__bio" itemprop="description">
        Kerrie is an ARS SCINet postdoc in the research group of Dr. Deb Peters in Las Cruces, NM. Her M.S. and Ph.D. degrees are in Atmospheric Sciences and her research background is in climate modeling.
      </p>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      

      

      
        <li>
          <a href="mailto:mailto:someone@iastate.edu">
            <meta itemprop="email" content="mailto:someone@iastate.edu" />
            <i class="fas fa-fw fa-envelope-square" aria-hidden="true"></i> Email
          </a>
        </li>
      

      

      
        <li>
          <a href="https://twitter.com/someone" itemprop="sameAs">
            <i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter
          </a>
        </li>
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

<!-- Create a 2nd author for tutorials -->



<div itemscope itemtype="http://schema.org/Person">

  

  <div class="author__content">
    
      <h3 class="author__name" itemprop="name"></h3>
    
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
  </div>


  <article class="page" itemscope itemtype="http://schema.org/CreativeWork">
    <meta itemprop="headline" content="Premeeting">
    
    
    

    <div class="page__inner-wrap">
      

      <section class="page__content" itemprop="text">
        
        <h1 id="tutorial-3-deep-learning-for-images">Tutorial 3: Deep Learning for Images</h1>
<h2 id="laura-e-boucheron-electrical--computer-engineering-nmsu">Laura E. Boucheron, Electrical &amp; Computer Engineering, NMSU</h2>
<h3 id="october-2020">October 2020</h3>
<p>Copyright (C) 2020  Laura E. Boucheron</p>

<p>This information is free; you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation; either version 3 of the License, or (at your option) any later version.</p>

<p>This work is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.</p>

<p>You should have received a copy of the GNU General Public License along with this work; if not, If not, see <a href="https://www.gnu.org/licenses/">https://www.gnu.org/licenses/</a>.</p>

<h2 id="overview">Overview</h2>
<p>In this tutorial, we will introduce the basic structure and common components (convolutional layers, pooling layers, nonlinearities, fully connected layers, etc.) of deep learning networks through a combination of illustrations and hands-on implementation of a network.  By the end of this tutorial, we will have built from scratch a deep convolutional neural network to operate on the standard MNIST handwritten digits dataset.  We will then explore some ways of probing the characteristics of the trained network to help us debug common pitfalls in adapting network architectures. </p>

<p>This tutorial contains 7 sections:</p>
<ul>
  <li><strong>Section 0: Preliminaries</strong>: some notes on using this notebook, how to download the image dataset that we will use for this tutorial, and import commands for the libraries necessary for this tutorial</li>
  <li><strong>Section 1: The MNIST Dataset</strong> how to load the MNIST dataset and some ideas for visualization of the dataset</li>
  <li><strong>Section 2: Data Preprocessing (Dimensionality Wrangling)</strong> how to preprocess the MNIST dataset in preparation for using it to train a deep network, including dimensionality and intensity scaling of the images and coding of the labels</li>
  <li><strong>Section 3: Building a CNN for MNIST</strong> how to build a basic 2-layer CNN for classification of MNIST digits including definition of the network architecture, compilation, and training</li>
  <li>Detour to a powerpoint presentation to learn more about the different CNN layers which are currently training</li>
  <li><strong>Section 4: Testing the Trained CNN</strong> how to test the accuracy of the trained network and locate those images incorrectly classified</li>
  <li><strong>Section 5: Transfer Learning for MNIST</strong> how to adapt a previously trained network to a new dataset</li>
  <li><strong>Section 6: Saving a Trained Model</strong> how to save a trained model so that you can load it and use it later.</li>
</ul>

<p>There are a few subsections with the heading “<strong>Your turn</strong>” throughout this tutorial in which you will be asked to apply what you have learned.</p>

<p>Portions of this tutorial have been taken or adapted from https://elitedatascience.com/keras-tutorial-deep-learning-in-python and the documentation at https://keras.io.</p>

<h1 id="section-0-preliminaries">Section 0: Preliminaries</h1>
<h2 id="a-note-on-jupyter-notebooks">A Note on Jupyter Notebooks</h2>

<p>There are two main types of cells in this notebook: code and markdown (text).  You can add a new cell with the plus sign in the menu bar above and you can change the type of cell with the dropdown menu in the menu bar above.  As you complete this tutorial, you may wish to add additional code cells to try out your own code and markdown cells to add your own comments or notes.</p>

<p>Markdown cells can be augmented with a number of text formatting features, including</p>
<ul>
  <li>bulleted</li>
  <li>lists</li>
</ul>

<p>embedded $\LaTeX$, monotype specification of <code class="language-plaintext highlighter-rouge">code syntax</code>, <strong>bold font</strong>, and <em>italic font</em>.  There are many other features of markdown cells–see the jupyter documentation for more information.</p>

<p>You can edit a cell by double clicking on it.  If you double click on this cell, you can see how to implement the various formatting referenced above.  Code cells can be run and markdown cells can be formatted using Shift+Enter or by selecting the Run button in the toolbar above.</p>

<p>Once you have completed (all or part) of this notebook, you can share your results with colleagues by sending them the <code class="language-plaintext highlighter-rouge">.ipynb</code> file.  Your colleagues can then open the file and will see your markdown and code cells as well as any results that were printed or displayed at the time you saved the notebook.  If you prefer to send a notebook without results displayed (like this notebook appeared when you downloaded it), you can select (“Restart &amp; Clear Output”) from the Kernel menu above.  You can also export this notebook in a non-executable form, e.g., <code class="language-plaintext highlighter-rouge">.pdf</code> through the File, Save As menu.</p>

<h2 id="section-03a-import-necessary-libraries-for-users-using-a-local-machine">Section 0.3a Import Necessary Libraries (For users using a local machine)</h2>
<p>Here, at the top of the code, we import all the libraries necessary for this tutorial.  We will introduce the functionality of any new libraries throughout the tutorial, but include all import statements here as standard coding practice.  We include a brief comment after each library here to indicate its main purpose within this tutorial.</p>

<p>It would be best to run this next cell before the workshop starts to make sure you have all the necessary packages installed on your machine.</p>

<p>A few other notes:</p>
<ul>
  <li>After the first import of keras packages, you may get a printout in a pink box that states
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Using Theano backend
</code></pre></div>    </div>
    <p>or</p>
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Using TensorFlow backend
</code></pre></div>    </div>
  </li>
  <li>You may get one or more warnings complaining about various configs.  As long as you don’t get any errors, you should be good to go.  You can, if you wish, fix whatever is causing a warning at a later point in time.  I find it best to copy and paste the error warning itself into a Google search and tack on the OS in which you encountered the error.  Seldom have I encountered an error that someone else hasn’t encountered in my same OS.</li>
  <li>The last two lines in the following code cell import the MNIST and Fashion-MNIST datasets.  Those datasets can be downloaded directly from online, but the <code class="language-plaintext highlighter-rouge">keras</code> library also includes a tool to do just that.  After you have downloaded the dataset for the first time, <code class="language-plaintext highlighter-rouge">keras</code> will load the dataset from its local location.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span> <span class="c1"># mathematical and scientific functions
</span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span> <span class="c1"># visualization
</span>
<span class="c1"># format matplotlib options
</span><span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="n">plt</span><span class="p">.</span><span class="n">rcParams</span><span class="p">.</span><span class="n">update</span><span class="p">({</span><span class="s">'font.size'</span><span class="p">:</span> <span class="mi">20</span><span class="p">})</span>

<span class="kn">import</span> <span class="nn">keras.backend</span> <span class="c1"># information on the backend that keras is using
</span><span class="kn">from</span> <span class="nn">keras.utils</span> <span class="kn">import</span> <span class="n">np_utils</span> <span class="c1"># functions to wrangle label vectors
</span><span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span> <span class="c1"># the basic deep learning model
</span><span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Flatten</span><span class="p">,</span> <span class="n">Convolution2D</span><span class="p">,</span> <span class="n">MaxPooling2D</span> <span class="c1"># important CNN layers
</span><span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">load_model</span> <span class="c1"># to load a pre-saved model (may require hdf libraries installed)
</span>
<span class="kn">from</span> <span class="nn">keras.datasets</span> <span class="kn">import</span> <span class="n">mnist</span> <span class="c1"># the MNIST dataset
</span><span class="kn">from</span> <span class="nn">keras.datasets</span> <span class="kn">import</span> <span class="n">fashion_mnist</span> <span class="c1"># the Fashion-MNIST dataset
</span></code></pre></div></div>

<h2 id="section-03b-build-the-conda-environment-for-users-using-the-ars-hpc-ceres-with-jupyterlab">Section 0.3b Build the Conda Environment (For users using the ARS HPC Ceres with JupyterLab)</h2>
<p>Open a terminal from inside JupyterLab (File &gt; New &gt; Terminal) and type the following commands</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>source activate
wget https://kerriegeil.github.io/NMSU-USDA-ARS-AI-Workshops/aiworkshop.yml
conda env create --prefix /project/your_project_name/envs/aiworkshop -f aiworkshop.yml
</code></pre></div></div>
<p>This will build the environment in one of your project directories. It may take 5 minutes to build the Conda environment.</p>

<p>See https://kerriegeil.github.io/NMSU-USDA-ARS-AI-Workshops/setup/ for more information.</p>

<p>When the environment finishes building, select this environment as your kernel in your Jupyter Notebook (click top right corner where you see Python 3, select your new kernel from the dropdown menu, click select)</p>

<p>You will want to do this BEFORE the workshop starts.</p>

<p>A few other notes:</p>
<ul>
  <li>After the first import of keras packages, you may get a printout in a pink box that states
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Using Theano backend
</code></pre></div>    </div>
    <p>or</p>
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Using TensorFlow backend
</code></pre></div>    </div>
  </li>
  <li>You may get one or more warnings complaining about various configs.  As long as you don’t get any errors, you should be good to go.  You can, if you wish, fix whatever is causing a warning at a later point in time.  I find it best to copy and paste the error warning itself into a Google search and tack on the OS in which you encountered the error.  Seldom have I encountered an error that someone else hasn’t encountered in my same OS.</li>
  <li>The last two lines in the following code cell import the MNIST and Fashion-MNIST datasets.  Those datasets can be downloaded directly from online, but the <code class="language-plaintext highlighter-rouge">keras</code> library also includes a tool to do just that.  After you have downloaded the dataset for the first time, <code class="language-plaintext highlighter-rouge">keras</code> will load the dataset from its local location.</li>
</ul>

<h1 id="section-1-the-mnist-dataset">Section 1: The MNIST Dataset</h1>

<h2 id="11-importing-the-mnist-dataset">1.1 Importing the MNIST dataset</h2>
<p>The line in the code cell above that reads <code class="language-plaintext highlighter-rouge">from keras.datasets import mnist</code> has loaded the <code class="language-plaintext highlighter-rouge">keras</code> package that interfaces with the local copy of MNIST dataset.</p>

<h3 id="printing-out-the-current-backend">Printing out the current backend</h3>
<p>Before we get going, let’s check which backend keras is using. All subsequent instructions should be valid for either <code class="language-plaintext highlighter-rouge">tensorflow</code> or <code class="language-plaintext highlighter-rouge">theano</code>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">keras</span><span class="p">.</span><span class="n">backend</span><span class="p">.</span><span class="n">backend</span><span class="p">())</span>
</code></pre></div></div>

<h3 id="a-note-on-other-standard-datasets-included-in-keras">A note on other standard datasets included in keras</h3>
<p>As a note, there are other datasets available as part of <code class="language-plaintext highlighter-rouge">keras.datasets</code>, see https://keras.io/datasets/ for more information.</p>

<h2 id="12-load-training-and-test-data">1.2 Load training and test data</h2>
<p>Now we can use the <code class="language-plaintext highlighter-rouge">mnist.load_data</code> function to read in the standard training data and test data.  The first time you run the following command you will see a printout of the download progress.  Subsequent times you run the command, you will not see any printout as the data will be loaded from where <code class="language-plaintext highlighter-rouge">keras</code> stored it locally on your computer.  The <code class="language-plaintext highlighter-rouge">mnist.load_data</code> function outputs <code class="language-plaintext highlighter-rouge">numpy</code> arrays.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">mnist</span><span class="p">.</span><span class="n">load_data</span><span class="p">()</span>
</code></pre></div></div>

<h3 id="a-note-on-the-variable-name-conventions">A note on the variable name conventions</h3>
<p>In loading the MNIST data, we are storing the data (images) in <code class="language-plaintext highlighter-rouge">X_train</code> and <code class="language-plaintext highlighter-rouge">X_test</code> and the corresponding labels in <code class="language-plaintext highlighter-rouge">y_train</code> and <code class="language-plaintext highlighter-rouge">y_test</code>.  It is common convention to label the input data with a capital ‘X’ and the labels with a lowercase ‘y’.  Since these data are images which can be represented as arrays, the convention of using ‘X’ and ‘y’ comes from matrix notation where vectors are assigned a lowercase variable and matrices an uppercase variable.</p>

<h2 id="13-checking-dimensionality-of-the-mnist-data-variables">1.3 Checking dimensionality of the MNIST data variables</h2>
<p>We know that the MNIST dataset consists of 70,000 examples of $28\times28$ pixels images of handwritten digits from 0-9.  We also know that there are 60,000 images reserved for training and 10,000 reserved for testing.  As such, we expect that the dimensionality of <code class="language-plaintext highlighter-rouge">X_train</code> and <code class="language-plaintext highlighter-rouge">X_test</code> to reflect this.  We print the shape of the two variables.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="s">'The dimensions of X_train are:'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">X_train</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'The dimensions of X_test are:'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">X_test</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></div>

<p>We also check the variable types of <code class="language-plaintext highlighter-rouge">X_train</code> and <code class="language-plaintext highlighter-rouge">X_test</code>.  Since the <code class="language-plaintext highlighter-rouge">mnist.load_data</code> function outputs <code class="language-plaintext highlighter-rouge">numpy</code> arrays, we need to use the <code class="language-plaintext highlighter-rouge">dtype</code> method to query the variable type.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="s">'The variable type of X_train is:'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">X_train</span><span class="p">.</span><span class="n">dtype</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'The variable type of X_test is:'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">X_test</span><span class="p">.</span><span class="n">dtype</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="a-note-on-tensors">A note on tensors</h3>
<p>In the literature and documentation related to deep learning, you will see the word “tensor” quite often.  We have just encountered our first tensors.  Think of tensors as multidimensional arrays.  <code class="language-plaintext highlighter-rouge">X_train</code> took the 60,000 $28\times28$ 2D pixel arrays, each of which represents an image, and stacked them to create a 3D array (tensor).  Before we’re done here, we’ll add a fourth dimension to <code class="language-plaintext highlighter-rouge">X_train</code> and <code class="language-plaintext highlighter-rouge">X_test</code>.</p>

<h2 id="14-visualizing-an-mnist-image">1.4 Visualizing an MNIST image</h2>
<p>From these dimensions, it appears that the first dimension indexes the sample (image) and the second and third dimensions index the spatial dimensions of the image.  It also appears that the images are <code class="language-plaintext highlighter-rouge">uint8</code>. We can check this assumption by visualizing one of the samples of <code class="language-plaintext highlighter-rouge">X_train</code>.  In this case we look at the first image in <code class="language-plaintext highlighter-rouge">X_train</code>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">cmap</span><span class="o">=</span><span class="s">'gray'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<h2 id="-your-turn-"><span style="color:Green"> Your turn: </span></h2>
<p>Look at some other images in <code class="language-plaintext highlighter-rouge">X_train</code> or <code class="language-plaintext highlighter-rouge">X_test</code>.  Does there appear to be any order in which the digits appear?</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>

<h2 id="15-mnist-label-vectors">1.5 MNIST label vectors</h2>
<p>The <code class="language-plaintext highlighter-rouge">y_train</code> variable contains the label, or the “truth” of what is represented in the image.  We can print out the label for the same image we visualized above (the first image in <code class="language-plaintext highlighter-rouge">X_train</code>).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">y_train</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</code></pre></div></div>

<p>This indicates that the image we plotted above corresponds to a ground truth label of ‘5’.</p>

<h2 id="-your-turn--1"><span style="color:Green"> Your turn: </span></h2>
<p>Revise your code from above to title your plot with the ground truth label.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>

<h2 id="15-a-visualization-of-the-digit-variation-in-mnist">1.5 A visualization of the digit variation in MNIST</h2>
<p>In addition to providing the labels for training a supervised classifier, the label vectors provide an important way to index into our dataset.  The following subsection illustrates one use of the label vector.</p>

<p>We can get a brief sense of the sort of variation included in this dataset by plotting 10 examples for each of the digits.  The following code makes use of the <code class="language-plaintext highlighter-rouge">X_train</code> variable and also the corresponding labels in <code class="language-plaintext highlighter-rouge">y_train</code>.</p>

<p>In the following code, we loop over the 10 digits using variable <code class="language-plaintext highlighter-rouge">d</code> and over 10 examples using variable <code class="language-plaintext highlighter-rouge">k</code>.  We plot the first 10 examples for each digit.  Let’s take a more careful look at the syntax <code class="language-plaintext highlighter-rouge">X_train[np.where(y_train==d)[0][k],:,:]</code></p>
<ul>
  <li>the <code class="language-plaintext highlighter-rouge">np.where(y_train==d)</code> finds those indexes where the ground truth indicates that we have a specific digit</li>
  <li>the <code class="language-plaintext highlighter-rouge">np.where</code> command returns a tuple; in this case there is only one dimension to the tuple, so we pull of the first dimension, so we have <code class="language-plaintext highlighter-rouge">np.where(y_train==d)[0]</code></li>
  <li>we now pull off the <code class="language-plaintext highlighter-rouge">k</code>-th index, so we have <code class="language-plaintext highlighter-rouge">np.where(y_train==d)[0][k]</code></li>
  <li>now we need to grab the image corresponding to the <code class="language-plaintext highlighter-rouge">k</code>-th instance of the digit <code class="language-plaintext highlighter-rouge">d</code>, and we have <code class="language-plaintext highlighter-rouge">X_train[np.where(y_train==d)[0][k],:,:]</code></li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">20</span><span class="p">))</span>
<span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">10</span><span class="p">):</span> <span class="c1"># loop over the digits 0 through 9
</span>    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">10</span><span class="p">):</span> <span class="c1"># choose 10 example images for each digit
</span>        <span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="n">d</span><span class="o">*</span><span class="mi">10</span><span class="o">+</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># select the current subplot
</span>        <span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">where</span><span class="p">(</span><span class="n">y_train</span><span class="o">==</span><span class="n">d</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="n">k</span><span class="p">],:,:],</span><span class="n">cmap</span><span class="o">=</span><span class="s">'gray'</span><span class="p">)</span> <span class="c1"># plot the image
</span>        <span class="n">plt</span><span class="p">.</span><span class="n">axis</span><span class="p">(</span><span class="s">'off'</span><span class="p">)</span>
</code></pre></div></div>

<h1 id="section-2-data-preprocessing-dimensionality-wrangling">Section 2: Data Preprocessing (Dimensionality Wrangling)</h1>

<h2 id="21-input-data-dimensionality-considerations">2.1 Input data dimensionality considerations</h2>
<p><code class="language-plaintext highlighter-rouge">keras</code> with the <code class="language-plaintext highlighter-rouge">theano</code> backend expects input to be tensors of the form samples $\times$ channels $\times$ height $\times$ width (<code class="language-plaintext highlighter-rouge">'channels_first'</code>) or samples $\times$ height $\times$ width $\times$ channels (<code class="language-plaintext highlighter-rouge">'channels_last'</code>).</p>

<p>MNIST images are one channel (grayscale), but we don’t see that explicitly represented in the shape of <code class="language-plaintext highlighter-rouge">X_train</code> or <code class="language-plaintext highlighter-rouge">X_test</code>.  Thus, we need to add a dimension to the <code class="language-plaintext highlighter-rouge">X_train</code> and <code class="language-plaintext highlighter-rouge">X_test</code> tensors to have the proper shape.</p>

<p>We can do this with the <code class="language-plaintext highlighter-rouge">reshape</code> command.  We choose the <code class="language-plaintext highlighter-rouge">'channels_last'</code> option and and tack on the channel as the fourth dimension.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X_train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X_test</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<p>Now when we check the shape, we find the expected form samples $\times$ height $\times$ width $\times$ channels.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="s">'The dimensions of X_train are:'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">X_train</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'The dimensions of X_test are:'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">X_test</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></div>

<p>We note that there is a default assumption of either <code class="language-plaintext highlighter-rouge">'channels_last'</code> or <code class="language-plaintext highlighter-rouge">'channels_first'</code> for each deep learning framework such as <code class="language-plaintext highlighter-rouge">theano</code> or <code class="language-plaintext highlighter-rouge">tensorflow</code>.  To avoid potential misinterpretation, we will explicitly specify <code class="language-plaintext highlighter-rouge">data_format='channels_last'</code> in our <code class="language-plaintext highlighter-rouge">keras</code> code below.</p>

<h3 id="a-note-on-the-importance-of-dimensionality">A note on the importance of dimensionality</h3>
<p>This is the first example of the care with which we need to consider the shape/dimensionality of our data.  This example is specific to <code class="language-plaintext highlighter-rouge">keras</code>, but the general principles here are similar for other deep learning frameworks, e.g., <code class="language-plaintext highlighter-rouge">tensorflow</code>, <code class="language-plaintext highlighter-rouge">caffe</code>, <code class="language-plaintext highlighter-rouge">pytorch</code>.</p>

<h2 id="-your-turn--2"><span style="color:Green"> Your turn: </span></h2>
<p>Above, you worked with the original <code class="language-plaintext highlighter-rouge">X_train</code> and <code class="language-plaintext highlighter-rouge">X_test</code> arrays as loaded by <code class="language-plaintext highlighter-rouge">keras</code>.  Now we have expanded the dimensions of those arrays.  Does your visualization code from above still work?</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>

<p>Depending on your library versions, you may have found that your visualization code from above no longer works.  If you get an error, it is likely similar to</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>TypeError: Invalid shape (28,28,1) for image data
</code></pre></div></div>
<p>when you try to visualize one of the MNIST images.  This error is due to the very fact that we explicitly expanded the dimensions to make <code class="language-plaintext highlighter-rouge">keras</code> happy.</p>

<h2 id="-your-turn--3"><span style="color:Green"> Your turn: </span></h2>
<p>Modify your code to work with the newly shaped <code class="language-plaintext highlighter-rouge">X_train</code> and <code class="language-plaintext highlighter-rouge">X_test</code> arrays.  The <code class="language-plaintext highlighter-rouge">np.squeeze</code> method for numpy arrays will likely be of use here: it removes single-dimensional entries from the shape of an array.  Note–you do not want to actually modify the shape of <code class="language-plaintext highlighter-rouge">X_train</code> or <code class="language-plaintext highlighter-rouge">X_test</code> here.  Your goal is to modify the visualization code to deal with the singleton dimensions.  Even if you were able to runt he code above, it is a good exercise to learn the usage of <code class="language-plaintext highlighter-rouge">np.squeeze</code> as other functions may grumble about singleton dimensions in the future.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>

<h2 id="22-input-data-intensity-scaling-considerations">2.2 Input data intensity scaling considerations</h2>
<p>We noted earlier that <code class="language-plaintext highlighter-rouge">X_train</code> and <code class="language-plaintext highlighter-rouge">X_test</code> are of variable type <code class="language-plaintext highlighter-rouge">uint8</code>.  It is considered best practice to normalize the range of your input data, commonly to $[0,1]$.  Back in the world of classical machine learning, this avoids a specific feature dominating the classification simply because it is larger.  In deep learning, continuing this convention allows for more consistency and robustness in the computation of the various gradients during training.  The risk of overflow (exceeding the capabilities of a variable type to represent a very large number) or underflow (exceeding the capabilities of a variable type to represent a very small, i.e., close to zero, number) is very real in deep learning.</p>

<h2 id="-your-turn--4"><span style="color:Green"> Your turn: </span></h2>
<p>Before we normalize the input data intensity, we should double check that the variables are within the range we expect.  Verify that <code class="language-plaintext highlighter-rouge">X_train</code> and <code class="language-plaintext highlighter-rouge">X_test</code> are within the expected range of [0,255] for a <code class="language-plaintext highlighter-rouge">uint8</code> variable.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>

<h3 id="casting-the-data-as-float">Casting the data as float</h3>
<p>Here, we cast the <code class="language-plaintext highlighter-rouge">numpy</code> arrays as <code class="language-plaintext highlighter-rouge">float32</code> and divide by the maximum we expect for a <code class="language-plaintext highlighter-rouge">uint8</code> variable (255).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">.</span><span class="n">astype</span><span class="p">(</span><span class="s">'float32'</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">.</span><span class="n">astype</span><span class="p">(</span><span class="s">'float32'</span><span class="p">)</span>
<span class="n">X_train</span> <span class="o">/=</span> <span class="mi">255</span>
<span class="n">X_test</span> <span class="o">/=</span> <span class="mi">255</span>
</code></pre></div></div>

<h2 id="-your-turn--5"><span style="color:Green"> Your turn: </span></h2>
<p>Check the range of the normalized <code class="language-plaintext highlighter-rouge">X_train</code> and <code class="language-plaintext highlighter-rouge">X_test</code> arrays to verify that they are now in the range [0,1].</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>

<h3 id="a-note-on-other-common-data-preprocessing-methods">A note on other common data preprocessing methods</h3>
<p>There are a suite of common data preprocessing methods.  Most of these involve some form of statistical normalization.  For example, we might scale our data to have a mean of 0 and a standard deviation of 1.  Or we might whiten the data to make it more normally distributed.  Here we have considered a simple range normalization, but note that other standard preprocessing routines exist.  See https://keras.io/preprocessing/image/ for some examples of other preprocessing methods and syntax for the built-in functions in <code class="language-plaintext highlighter-rouge">keras</code> to perform those methods.</p>

<h3 id="a-note-on-the-use-of-float32-or-float64">A note on the use of float32 or float64</h3>
<p>In this case we cast as <code class="language-plaintext highlighter-rouge">float32</code> since that is already overkill for <code class="language-plaintext highlighter-rouge">uint8</code> variables and it will take up less memory than casting those arrays as <code class="language-plaintext highlighter-rouge">float64</code>.  We note, however, that if your data is natively <code class="language-plaintext highlighter-rouge">float64</code>, you probably want to leave it as such.</p>

<h2 id="23-label-vector-coding">2.3 Label vector coding</h2>
<h3 id="231-dimensionality-of-the-loaded-label-vectors">2.3.1 Dimensionality of the loaded label vectors</h3>
<p>Now we turn our attention to the label vectors.  We check the shape of the label vectors.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="s">'The dimensions of y_train are:'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">y_train</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'The dimensions of y_test are:'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">y_test</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></div>

<p>We have already looked at entries in <code class="language-plaintext highlighter-rouge">y_train</code> and <code class="language-plaintext highlighter-rouge">y_test</code> and noted that they are integers that (at least in this case) directly correspond to the digit that the image represents.  More on this in a bit…</p>

<p>However… <code class="language-plaintext highlighter-rouge">keras</code> (and many other common classification and deep learning frameworks) expects labels of shape $N_\text{samples}\times N_\text{classes}$.  We see that we are okay in terms of $N_\text{samples}$ (60,000 for training and 10,000 for test), but we have an empty second dimension. We somehow need to reconfigure the label vectors so that they will be $60,000\times10$ for <code class="language-plaintext highlighter-rouge">y_train</code> and $10,000\times10$ for <code class="language-plaintext highlighter-rouge">y_test</code>.  How do we get to a $60,000\times10$ array for the labels?</p>

<h3 id="232-a-brief-introduction-to-one-hot-coding">2.3.2 A brief introduction to one-hot coding</h3>
<p>What we really need is a representation of the label vectors that better matches the typical output of a neural network.  The output layer of a neural network classifier will have $N_\text{classes}$ nodes.  In a typical application, the last layer is a <code class="language-plaintext highlighter-rouge">softmax</code> layer which outputs <em>probabilities of a sample belonging to each of the classes</em> $C_j,~j=0,\ldots,N_\text{classes}-1$.  Thus, the <code class="language-plaintext highlighter-rouge">softmax</code> layer for an MNIST digit classification will have form \([p(C_0),p(C_1),p(C_2),p(C_3),p(C_4),p(C_5),p(C_6),p(C_7),p(C_8),p(C_9)]^T.\)  A simple argmax predicts the label as the class with the highest probability, i.e., $\hat{y}=\text{argmax}_j p(C_j)$.  This means that if the network is absolutely 100% certain that a sample is a digit ‘3’, all coefficients in the softmax layer will be zero except the coefficient corresponding to the digit ‘3’, i.e., \([0,0,0,1,0,0,0,0,0,0]^T\) with $\hat{y}=3$.</p>

<p>This gives us insight into how to “encode” the <em>input</em> label vector.  We want a value of 1 for the given class and zeros everywhere else; this is also known as <strong>one-hot coding</strong>.</p>

<h3 id="233-what-do-labels-mean">2.3.3 What do labels “mean”?</h3>
<p>If we print the first ten labels in <code class="language-plaintext highlighter-rouge">y_train</code>, we see that the labels are reported as the digit itself.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="s">'The first ten entries of y_train are:'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">y_train</span><span class="p">[:</span><span class="mi">10</span><span class="p">])</span>
</code></pre></div></div>

<p>In this case there is a very direct and obvious relationship between the label and the meaning.  If <code class="language-plaintext highlighter-rouge">y_train==3</code>, the data is an image of the numeral three.</p>

<h3 id="a-very-important-note-on-the-abstractness-of-labels">A very important note on the abstractness of labels</h3>
<p>It is important to keep in mind, however, that these labels are a very abstract concept–when we see the ASCII character ‘3’ printed in the first ten entries of <code class="language-plaintext highlighter-rouge">y_train</code> above, we interpret that to mean ‘an image of the numeral three.’  We could just as easily have labeled the images of the numeral three with the label ‘hamster’ and <em>nothing</em> about the following code would change.  The performance we will see below on the ability to correctly classify all images of the numeral 3 would be identical.  The only difference is that the network would very cheerfully report that an image of the numeral three is a ‘hamster’ instead of a ‘3’.  And it would be correct because we would have told it that images of the numeral three are ‘hamsters.’</p>

<p>This highlights the importance of leveraging humans to provide labels for the training data.  It is the humans that are providing the abstract intepretation of what those images represent.  Computers, however, only understand numbers.  So we need to find some means to translate our abstract notion of the classes of the input data to something numerical for the computer to interpret.</p>

<p>As a more concrete example of this abstractness of the labels, consider the Fashion-MNIST dataset (see also https://keras.io/datasets/).  This dataset was designed to be a drop-in replacement for MNIST.  The dimensionality is exactly the same (60,000 28$\times$28 pixel training images and 10,000 28$\times$28 pixel testing images), but the images are grayscale images of clothing articles.  Thus in the Fashion-MNIT dataset, if ground truth label is specified as ‘3’, instead of interpreting that as ‘an image of the ‘numeral three,’ you interpret that as ‘an image of a dress.’</p>

<p>A convenient and common translation is to these one-hot coded vectors.  Different frameworks and different networks may have different conventions.</p>

<h3 id="234-converting-labels-to-one-hot-coding">2.3.4 Converting labels to one-hot coding</h3>
<p>We will use the <code class="language-plaintext highlighter-rouge">keras</code> function <code class="language-plaintext highlighter-rouge">np_utils.to_categorical</code> to convert the label vector to a one-hot vector.  We specifying <code class="language-plaintext highlighter-rouge">y_train</code> or <code class="language-plaintext highlighter-rouge">y_test</code> as input and denote the one-hot label vector with a capital <code class="language-plaintext highlighter-rouge">Y</code> to remind ourselves that this is now actually a matrix of probabilities and thus a very different representation than the original label vector.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">Y_train</span> <span class="o">=</span> <span class="n">np_utils</span><span class="p">.</span><span class="n">to_categorical</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">Y_test</span> <span class="o">=</span> <span class="n">np_utils</span><span class="p">.</span><span class="n">to_categorical</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
</code></pre></div></div>

<p>Let’s check the dimensionality of these new one-hot labels <code class="language-plaintext highlighter-rouge">Y_train</code> and <code class="language-plaintext highlighter-rouge">Y_test</code>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="s">'The dimensions of Y_train are:'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">Y_train</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'The dimensions of Y_test are:'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">Y_test</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></div>

<p>We note that the first dimension of <code class="language-plaintext highlighter-rouge">Y_train</code> and <code class="language-plaintext highlighter-rouge">Y_test</code> correspond to the sample and the second dimension consists of 10 entries.  Let’s look at the one-hot label for the first 10 samples in <code class="language-plaintext highlighter-rouge">Y_train</code> and compare to the first 10 samples in the original label vector <code class="language-plaintext highlighter-rouge">y_train</code>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="s">'The first ten entries of y_train (original label vector) are:'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">y_train</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">10</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="s">'The argmax of the first ten entries of Y_train (one-hot label vector) are:'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">Y_train</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">10</span><span class="p">,:])</span>
</code></pre></div></div>

<h2 id="-your-turn--6"><span style="color:Green"> Your turn: </span></h2>
<p>Verify to yourself that the correct entries in the one-hot label vector are hot.</p>

<h3 id="235-converting-labels-from-one-hot-coding">2.3.5 Converting labels from one-hot coding</h3>
<p>We can double check ourselves by applying an argmax to the one-hot labels.  We expect to get back the original labels.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="s">'The first ten entries of y_train (original label vector) are:'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">y_train</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">10</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="s">'The first ten entries of Y_train (one-hot label vector) are:'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">Y_train</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">10</span><span class="p">,:],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
</code></pre></div></div>

<p>We find that we do get back the original labels.</p>

<h1 id="section-3-building-a-cnn-for-mnist">Section 3: Building a CNN for MNIST</h1>

<p>Now we’ve loaded and preprocessed the input data (samples <code class="language-plaintext highlighter-rouge">X_train</code> and labels <code class="language-plaintext highlighter-rouge">y_train</code>) needed to train a deep learning network.  We need to decide the specific architecture of the network itself.  We begin here with a simple 2-layer network.  This network will result in approximately 95% accuracy on the training data after several epochs, but can take a few minutes per epoch to run on a CPU.  As such, we will set this up to run and then cycle back around to understand the details as it is training.</p>

<p>Within each epoch of training, the entire training dataset is visited once.  Thus, an epoch can be thought of in the general sense of an iteration.  Deep learning uses the distinct terminology of epoch to specifically mean the one visit of the entire training set.  Within each epoch, you have batches of the input data.  The decomposition of an epoch into multiple batches is particularly important for very large datasets that cannot fit into working memory.</p>

<h2 id="31-import-necessary-keras-library-functions">3.1 Import necessary keras library functions</h2>
<p>In Section 0.3 we directly imported only those functions we use from <code class="language-plaintext highlighter-rouge">keras</code> to make our code more compact.</p>

<h2 id="32-define-the-model-architecture">3.2 Define the model architecture</h2>
<p>Next we define our first model, which we call <code class="language-plaintext highlighter-rouge">model1</code>.  We’ll cycle back to understand the components of this model after we set it training, but also include some descriptions here:</p>
<ul>
  <li>The <code class="language-plaintext highlighter-rouge">Sequential</code> model is the base class used in <code class="language-plaintext highlighter-rouge">keras</code> to define a sequential stack of layers</li>
  <li>The <code class="language-plaintext highlighter-rouge">Convolution2D</code> layer defines a typical convolution layer.  This layer takes a tensor of images as input and outputs a tensor of images.  Note that you need to define the input shape for the first convolutional layer $28\times28\times1$ in this case.  The input shape for all subsequent layers is automatically inferred to be the same as the output shape for the previous layer.  We explicitly specify <code class="language-plaintext highlighter-rouge">'channels_last'</code> for the <code class="language-plaintext highlighter-rouge">data_format</code> since that is how we defined our input data.  Note that for CNNs we generally only count the convolutional layers when reporting on the depth of the network.</li>
  <li>The <code class="language-plaintext highlighter-rouge">MaxPooling2D</code> layer reduces the spatial dimensions of the input tensor.  We again explicitly specify <code class="language-plaintext highlighter-rouge">'channels_last'</code> for the <code class="language-plaintext highlighter-rouge">data_format</code>.</li>
  <li>The <code class="language-plaintext highlighter-rouge">Flatten</code> layer essentially reshapes the dimensions of the data.  In this case it takes the $28\times28\times32$ tensor output from the second convolutional layer and reshapes it into a length $28<em>28</em>32=25088$ vector.</li>
  <li>The <code class="language-plaintext highlighter-rouge">Dense</code> layer is the layer type for fully connected (i.e., dense) layers.  This type of layer defines a connection from all nodes in the previous layer to all nodes in the subsequent layer.  The first layer defined here takes the 25088 inputs and outputs 128 values.  The second fully connected layer takes those 128 as input and outputs 10 values.</li>
  <li>Note that the size of the output layer is consistent with the number of classes in our dataset (10 in this case) and that we have specified a <code class="language-plaintext highlighter-rouge">'softmax'</code> activation. This means that the output will be the probability of an example belonging to each of the 10 classes.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model1</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model1</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Convolution2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">data_format</span><span class="o">=</span><span class="s">'channels_last'</span><span class="p">))</span>
<span class="n">model1</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Convolution2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">,</span> <span class="n">data_format</span><span class="o">=</span><span class="s">'channels_last'</span><span class="p">))</span>
<span class="n">model1</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span><span class="n">data_format</span><span class="o">=</span><span class="s">'channels_last'</span><span class="p">))</span>
<span class="n">model1</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Flatten</span><span class="p">())</span>
<span class="n">model1</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">))</span>
<span class="n">model1</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'softmax'</span><span class="p">))</span>
</code></pre></div></div>

<h2 id="33-compile-the-model">3.3 Compile the model</h2>
<p>Next we need to compile the model before we can train it.  This requires specification of several parameters including the <code class="language-plaintext highlighter-rouge">loss</code>, the <code class="language-plaintext highlighter-rouge">optimizer</code> and the <code class="language-plaintext highlighter-rouge">metrics</code>.  Again, we will cycle back to understand these after we set it training.  We specify a minimum of options here, including:</p>
<ul>
  <li>The loss function which is what the network uses to gauge its performance as it trains.  In this case we use <code class="language-plaintext highlighter-rouge">'categorical_crossentropy'</code> which is a common loss function for multi-class classification problems.  This loss expects labels in one-hot coded format.</li>
  <li>The optimizer which is how the network adjusts its learning as it trains.  In this case we use the <code class="language-plaintext highlighter-rouge">'adam'</code> optimizer which is a good optimizer in the absence of any other prefered optimizer.  The <code class="language-plaintext highlighter-rouge">'adam'</code> optimizer adjusts the learning rate throughout the training process to help convergence.</li>
  <li>The <code class="language-plaintext highlighter-rouge">metrics</code> which are the “human-interpretable” measurements of network performance.  Here we request the accuracy which will be a the percentage of correctly classified digits.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model1</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s">'categorical_crossentropy'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s">'adam'</span><span class="p">,</span><span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span>
</code></pre></div></div>

<h2 id="34-train-the-model">3.4 Train the model</h2>
<p>Now we finally start the actual training of this model.  We input the <code class="language-plaintext highlighter-rouge">X_train</code> and <code class="language-plaintext highlighter-rouge">Y_train</code> variables that we worked with above, and specify a few simulation parameters such as <code class="language-plaintext highlighter-rouge">batch_size</code> and <code class="language-plaintext highlighter-rouge">epochs</code> which we will cycle back to in a while.  We specify <code class="language-plaintext highlighter-rouge">verbose=1</code> in order to print out status so we can keep track of where we are in the training process.</p>

<p>You may get one or more warnings, but as long as you don’t get any errors, you should see 
something of the form</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 1/10
38208/60000 [==================&gt;..........] - ETA: 1:12 - loss: 0.1849 - acc: 0.9448
</code></pre></div></div>

<p>We have specified a total of 1 epoch, so the ETA specified at the beginning of the current epoch is approximately the total time the training is expected to take.  How long the training takes is very dependent on the hardware and how well that hardware is configured to perform the sort of computation required for CNN training.  On my desktop machine (AMD Ryzen 7 2700X 4.3 GHz processor), the training took about 3.5 minutes on all 8 CPUs.  While this might be longer than the average person is accustomed to waiting for a computer to finish processing, this is actually a very reasonable time to train a complete deep network.  This is because the MNIST dataset is not too large, nor is the network we specified.  Ordinarily, we would (need to) run the training for more than one epoch.  For MNIST, however, we can converge to a very good accuracy within one epoch.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model1</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<p>There are some other issues related to testing the trained network that we will return to in Section 4.  For the remainder of this section, we focus on deepening our understanding of this model that we have trained on MNIST.</p>

<h2 id="35-some-common-errors-in-defining-compiling-and-training-the-model">3.5 Some Common Errors in Defining, Compiling, and Training the Model</h2>
<p>Error reporting is not always the most elucidating in deep learning models.  Here we explore some common errors in model definition, compilation, and training.  Below, we have copied the definition, compilation, and training stages from above and named this new model <code class="language-plaintext highlighter-rouge">model2</code>.  You can copy and paste this code into subsequent code cells and modify different aspects of the three stages to explore the effects and/or error messages encountered.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model2</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model2</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Convolution2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">data_format</span><span class="o">=</span><span class="s">'channels_last'</span><span class="p">))</span>
<span class="n">model2</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Convolution2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">,</span> <span class="n">data_format</span><span class="o">=</span><span class="s">'channels_last'</span><span class="p">))</span>
<span class="n">model2</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span><span class="n">data_format</span><span class="o">=</span><span class="s">'channels_last'</span><span class="p">))</span>
<span class="n">model2</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Flatten</span><span class="p">())</span>
<span class="n">model2</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">))</span>
<span class="n">model2</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'softmax'</span><span class="p">))</span>

<span class="n">model2</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s">'categorical_crossentropy'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s">'adam'</span><span class="p">,</span><span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span>

<span class="n">model2</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="351-errors-that-actually-report-as-errors">3.5.1 Errors that actually report as errors</h2>
<p>The following errors should actually report as an error.  That error may or may not be particularly ellucidating in helping you find the source of the error if you weren’t aware of the source in advance.</p>

<h2 id="-your-turn--7"><span style="color:Green"> Your turn: </span></h2>
<p>What happens if you specify <code class="language-plaintext highlighter-rouge">data_format='channels_first'</code>?  How useful is the error in this case?</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>

<h2 id="-your-turn--8"><span style="color:Green"> Your turn: </span></h2>
<p>What happens if you forget the flatten layer?  How useful is the error in this case?</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>

<h2 id="-your-turn--9"><span style="color:Green"> Your turn: </span></h2>
<p>What happens if you specify an output layer that is not length 10?  How useful is the error in this case?</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>

<h2 id="352-errors-that-dont-appear-to-be-errors-at-first">3.5.2 Errors that don’t appear to be errors at first</h2>

<p>Sometimes, errors in your specification of the model will not result in an explicit coding error, which may cause further issues in debugging.  Here are two examples that we will explore further after we study more about testing models in Section 4.</p>

<p>What happens if you use a <code class="language-plaintext highlighter-rouge">'tanh'</code> activation instead of a <code class="language-plaintext highlighter-rouge">'softmax'</code> activation on the output layer?</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model3</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model3</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Convolution2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">data_format</span><span class="o">=</span><span class="s">'channels_last'</span><span class="p">))</span>
<span class="n">model3</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Convolution2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">,</span> <span class="n">data_format</span><span class="o">=</span><span class="s">'channels_last'</span><span class="p">))</span>
<span class="n">model3</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span><span class="n">data_format</span><span class="o">=</span><span class="s">'channels_last'</span><span class="p">))</span>
<span class="n">model3</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Flatten</span><span class="p">())</span>
<span class="n">model3</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">))</span>
<span class="n">model3</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'tanh'</span><span class="p">))</span>

<span class="n">model3</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s">'categorical_crossentropy'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s">'adam'</span><span class="p">,</span><span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span>

<span class="n">model3</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<p>What happens if we specify a <code class="language-plaintext highlighter-rouge">'binary_crossentropy'</code> loss function instead of <code class="language-plaintext highlighter-rouge">'categorical_crossentropy'</code>?</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model4</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model4</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Convolution2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">data_format</span><span class="o">=</span><span class="s">'channels_last'</span><span class="p">))</span>
<span class="n">model4</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Convolution2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">,</span> <span class="n">data_format</span><span class="o">=</span><span class="s">'channels_last'</span><span class="p">))</span>
<span class="n">model4</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span><span class="n">data_format</span><span class="o">=</span><span class="s">'channels_last'</span><span class="p">))</span>
<span class="n">model4</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Flatten</span><span class="p">())</span>
<span class="n">model4</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">))</span>
<span class="n">model4</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'softmax'</span><span class="p">))</span>

<span class="n">model4</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s">'binary_crossentropy'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s">'adam'</span><span class="p">,</span><span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span>

<span class="n">model4</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<h1 id="section-4-testing-the-trained-cnn">Section 4: Testing the Trained CNN</h1>

<h2 id="41-determining-accuracy-on-test-data">4.1 Determining accuracy on test data</h2>
<p>The accuracies that you see reported as the network trains are the accuracies on the <em>training</em> data.  This can be a good indication of the convergence of the network since you expect that the loss should decrease and accuracy should increase as training progresses.</p>

<p>There is concern, however, that the network has “learned the data” instead of learned a more general classifier.  That is why we set aside a separate test set.  All of the data in the test set were unseen in training and thus are brand new to the network.  If the network is good and has not overfit the training data (learned the training data), we expect to see a good accuracy on the test data.  We expect that the test accuracy will likely be a bit lower than the training accuracy.</p>

<p>We can take the trained model and evaluate it on a dataset using the <code class="language-plaintext highlighter-rouge">evaluate</code> method of the trained model.  As a sanity check, if we were to input the training data again, we would expect exactly the last accuracy reported in training.</p>

<p>We again use the <code class="language-plaintext highlighter-rouge">verbose=1</code> option here to track the progress of evaluating the model on all 10,000 test images.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">score</span> <span class="o">=</span> <span class="n">model1</span><span class="p">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>
</code></pre></div></div>

<p>Note that the test stage is very quick. The major computational overhead in deep learning is in training.  The operational use of the trained model is very computationally light.  On my desktop computer, using the CPU, all 10,000 test images were labeled and compared to their ground truth in 8s, or 840 $\mu$s per image.  This reported two values after completion.  We can check what those values are by looking at the <code class="language-plaintext highlighter-rouge">metrics_names</code> attribute of the model.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">model1</span><span class="p">.</span><span class="n">metrics_names</span><span class="p">)</span>
</code></pre></div></div>

<p>We note that these metrics are the loss and accuracy.  The loss is reported by default since that is the metric used by the network during training.  We requested that the network keep track of the additional metric of accuracy with the option <code class="language-plaintext highlighter-rouge">metrics=['accuracy']</code> when compiling the model.</p>

<h2 id="42-determining-the-predicted-labels">4.2 Determining the predicted labels</h2>
<h3 id="421-determining-the-one-hot-labels">4.2.1 Determining the one-hot labels</h3>
<p>We might want more information than just a summary of the accuracy.  If we output the predicted label for each of the test images, we can look more carefully at the performance of the network.  We use the <code class="language-plaintext highlighter-rouge">predict</code> method of the model.  This has to run all 10,000 test images through the trained network and determine the class for each image.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">Y_predict</span> <span class="o">=</span> <span class="n">model1</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span><span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<p>When we computed the one-hot coded label vector used to train the network, we began with the assumption that a one-hot form is consistent with the native output of the network.  We would thus expect that <code class="language-plaintext highlighter-rouge">Y_predict</code> is in a one-hot format.  We check this by printing the dimensions of <code class="language-plaintext highlighter-rouge">Y_predict</code>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">Y_predict</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">Y_predict</code> does have the dimensions we would expect for a one-hot coded label vector.  Similar to our process when we developed the one-hot coded vector <code class="language-plaintext highlighter-rouge">Y_test</code>, we can look at the first 10 entries of <code class="language-plaintext highlighter-rouge">Y_predict</code>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">Y_predict</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">10</span><span class="p">,:])</span>
</code></pre></div></div>

<p>At first glance, this form looks very different than those we saw for <code class="language-plaintext highlighter-rouge">Y_train</code>.  Remember, however, that with <code class="language-plaintext highlighter-rouge">Y_train</code> we knew exactly what the actual labels were.  Here, with <code class="language-plaintext highlighter-rouge">Y_predict</code>, the network is computing probabilities of the image belonging to each of the 10 classes.  If you pay careful attention to the exponents of the coefficients in each row of <code class="language-plaintext highlighter-rouge">Y_predict</code>, you will note that one coefficient is very close to 1 and the remainder are very close to zero.</p>

<p>In fact, most of these coefficients round to 1 and 0 if rounded to two decimal places:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nb">round</span><span class="p">(</span><span class="n">Y_predict</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">10</span><span class="p">,:],</span><span class="mi">2</span><span class="p">))</span>
</code></pre></div></div>

<h3 id="422-determining-the-numerical-class-labels">4.2.2 Determining the numerical class labels</h3>
<p>We can apply the argmax function to the one-hot label vector <code class="language-plaintext highlighter-rouge">Y_predict</code> to determine the class label for each sample.  Since this output will have a similar form to the original label vectors, we denote it as <code class="language-plaintext highlighter-rouge">y_predict</code>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">y_predict</span> <span class="o">=</span> <span class="n">Y_predict</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<p>If we print these numerical labels, we see that they correspond to the one-hot interpretation above.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">y_predict</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">10</span><span class="p">])</span>
</code></pre></div></div>

<h3 id="423-comparing-the-predicted-labels-to-the-ground-truth">4.2.3 Comparing the predicted labels to the ground truth</h3>
<p>The deterimination of accuracy requires a comparison of the predicted labels to the ground truth labels.  That is was is done “under the hood” when <code class="language-plaintext highlighter-rouge">keras</code> reports accuracy using the <code class="language-plaintext highlighter-rouge">evaluate</code> method of the model.  As a sanity check, we can compute the accuracy “by hand” using <code class="language-plaintext highlighter-rouge">y_predict</code> and <code class="language-plaintext highlighter-rouge">y_test</code>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">my_acc</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_predict</span><span class="o">==</span><span class="n">y_test</span><span class="p">).</span><span class="nb">sum</span><span class="p">()</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">y_predict</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'My accuracy computation says:'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">my_acc</span><span class="p">)</span>
</code></pre></div></div>

<p>We see that this value exactly matches that reported by <code class="language-plaintext highlighter-rouge">keras</code> above.</p>

<p>We can also use both <code class="language-plaintext highlighter-rouge">y_predict</code> and <code class="language-plaintext highlighter-rouge">y_test</code> to gain a bit more insight into the performance of the network.</p>

<p>As a very simple verification, we can print the first 10 labels of both <code class="language-plaintext highlighter-rouge">y_predict</code> and <code class="language-plaintext highlighter-rouge">y_train</code> and compare by eye.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="s">'Actual labels are:'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">y_test</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">10</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Predicted labels are:'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">y_predict</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">10</span><span class="p">])</span>
</code></pre></div></div>

<h3 id="424-investigate-errors-in-classification">4.2.4 Investigate errors in classification</h3>
<p>Looking more closely at those images that the network incorrectly classified can give us some insight in the robustness of the network.  If the incorrectly classified images are difficult images, we may have more confidence in the network than if it is incorrectly classifying obvious images (more fun examples of that tomorrow!).</p>

<p>We can find which images were incorrectly classified by the network by looking for those images where the predicted and ground truth labels do not match.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">incorrect_labels</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">where</span><span class="p">(</span><span class="n">y_predict</span><span class="o">!=</span><span class="n">y_test</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="s">'There are '</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">incorrect_labels</span><span class="p">))</span><span class="o">+</span><span class="s">' incorrectly classified images'</span><span class="p">)</span>
</code></pre></div></div>

<p>The code below visualizes the first 10 of these incorrectly classified images and titles the plots with both the correct and predicted label.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">15</span><span class="p">))</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">9</span><span class="p">):</span> <span class="c1"># choose 10 examples
</span>    <span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># select the current subplot
</span>    <span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">incorrect_labels</span><span class="p">[</span><span class="n">k</span><span class="p">],:,:]),</span><span class="n">cmap</span><span class="o">=</span><span class="s">'gray'</span><span class="p">)</span> <span class="c1"># plot the image
</span>    <span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Actual:'</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">y_test</span><span class="p">[</span><span class="n">incorrect_labels</span><span class="p">[</span><span class="n">k</span><span class="p">]])</span><span class="o">+</span><span class="s">' Predicted:'</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">y_predict</span><span class="p">[</span><span class="n">incorrect_labels</span><span class="p">[</span><span class="n">k</span><span class="p">]]))</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">axis</span><span class="p">(</span><span class="s">'off'</span><span class="p">)</span>
</code></pre></div></div>

<p>In many of these cases, the digits do not appear “typical” in form and it is thus not surprising that the network may have had difficulty correctly classifying them.  In most cases, it is also easy to postulate what structures in the image may have resulted in the incorrect classification that did result.</p>

<h2 id="-your-turn--10"><span style="color:Green"> Your turn: </span></h2>
<p>Explore the performance of <code class="language-plaintext highlighter-rouge">model3</code> in which we used a <code class="language-plaintext highlighter-rouge">'relu'</code> activation on the output layer and <code class="language-plaintext highlighter-rouge">model4</code> in which we used a <code class="language-plaintext highlighter-rouge">'binary_crossentropy'</code> loss.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>

<h1 id="section-5-transfer-learning">Section 5: Transfer Learning</h1>
<h2 id="51-applying-the-mnist-network-directly-to-fashion-mnist">5.1 Applying the MNIST Network Directly to Fashion-MNIST</h2>
<p>Here we look at what happens when we input data to a network that is completely different than what it has seen before.  To make our lives easier, we will use the Fashion-MNIST dataset which is designed as a dropin for the MNIST dataset.  This way, we don’t need to worry about as many details in the data preprocessing and can focus on the behavior of the network to completely different data.</p>

<p>We import and preprocess the Fashion-MNIST dataset in exactly the same way we did the MNIST data.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="n">X_train_f</span><span class="p">,</span> <span class="n">y_train_f</span><span class="p">),</span> <span class="p">(</span><span class="n">X_test_f</span><span class="p">,</span> <span class="n">y_test_f</span><span class="p">)</span> <span class="o">=</span> <span class="n">fashion_mnist</span><span class="p">.</span><span class="n">load_data</span><span class="p">()</span>
<span class="n">X_train_f</span> <span class="o">=</span> <span class="n">X_train_f</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X_train_f</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">X_train_f</span> <span class="o">=</span> <span class="n">X_train_f</span><span class="p">.</span><span class="n">astype</span><span class="p">(</span><span class="s">'float32'</span><span class="p">)</span>
<span class="n">X_train_f</span> <span class="o">/=</span> <span class="mi">255</span>
<span class="n">Y_train_f</span> <span class="o">=</span> <span class="n">np_utils</span><span class="p">.</span><span class="n">to_categorical</span><span class="p">(</span><span class="n">y_train_f</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">X_test_f</span> <span class="o">=</span> <span class="n">X_test_f</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X_test_f</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">X_test_f</span> <span class="o">=</span> <span class="n">X_test_f</span><span class="p">.</span><span class="n">astype</span><span class="p">(</span><span class="s">'float32'</span><span class="p">)</span>
<span class="n">X_test_f</span> <span class="o">/=</span> <span class="mi">255</span>
<span class="n">Y_test_f</span> <span class="o">=</span> <span class="n">np_utils</span><span class="p">.</span><span class="n">to_categorical</span><span class="p">(</span><span class="n">y_test_f</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
</code></pre></div></div>

<p>Let’s check the performance of the MNIST network on this new dataset.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">score</span> <span class="o">=</span> <span class="n">model1</span><span class="p">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test_f</span><span class="p">,</span> <span class="n">Y_test_f</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>
</code></pre></div></div>

<p>As a point of reference, since there are 10 classes in the Fashion-MNIST dataset, you would expect a random guess to yield approximately 10% accuracy.  We find about 8% accuracy (this may differ depending on exactly where your model converged to in training and may differ from run to run given the random initialization and randomization in assigning data to batches).  Why is the performance so bad?</p>

<p>Let’s look at one of the images from the Fashion-MNIST dataset.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">X_test_f</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span><span class="n">cmap</span><span class="o">=</span><span class="s">'gray'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="s">'This image is class '</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">y_test</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">+</span><span class="s">' in the Fashion-MNIST dataset'</span><span class="p">)</span>
</code></pre></div></div>

<p>We see that this is an image of a “sneaker,” which also corresponds to class 7 in the Fashion-MNIST dataset (see https://keras.io/datasets/ for the full list of class labels and descriptions).</p>

<p>Let’s see what class our digit MNIST network classifies this image as.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">Y_example</span> <span class="o">=</span> <span class="n">model1</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_f</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y_example</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">Y_example</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">y_example</span><span class="p">)</span>
</code></pre></div></div>

<p>This network has decided that this image of a “sneaker” is the digit “2” (the network usually converges to “2”, but may have converged to a different value depending on differences in training).  It has never seen a sneaker.  But it will still do its level best to match that sneaker to the closest thing it knows.  In this case, that is apparently a “2”.</p>

<h2 id="52-adapting-the-mnist-model-for-fashion-mnist-transfer-learning">5.2 Adapting the MNIST Model for Fashion-MNIST (Transfer Learning)</h2>

<p>In transfer learning, we can “transfer” knowledge learned in one domain (e.g., MNIST) to another domain (e.g., Fashion-MNIST).  The idea of transfer learning is predicated on the assumption that all images share the same basic primitives (edges, corners, etc.) which are essentially the features of images that we hand-designed in the second tutorial.  In transfer learning, we re-use those image primitives and only have to relearn how to combine those primitives together in order to correctly classify a new domain of images.  To do this, we will copy our MNIST <code class="language-plaintext highlighter-rouge">model1</code> architecture and “freeze” all layers except the last layer by setting the <code class="language-plaintext highlighter-rouge">trainable</code> attribute of layers to <code class="language-plaintext highlighter-rouge">False</code>.  All the parameters from the two convolutional layers and the first fully connected layer will remain in the state that we converged to when training the network on MNIST.  It is only that final fully connected layer that will change in order to (hopefully) learn to correctly classify the Fashion-MNIST data.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model1_f</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">models</span><span class="p">.</span><span class="n">clone_model</span><span class="p">(</span><span class="n">model1</span><span class="p">)</span>
<span class="n">model1_f</span><span class="p">.</span><span class="n">set_weights</span><span class="p">(</span><span class="n">model1</span><span class="p">.</span><span class="n">get_weights</span><span class="p">())</span>

<span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">model1_f</span><span class="p">.</span><span class="n">layers</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
    <span class="n">layer</span><span class="p">.</span><span class="n">trainable</span><span class="o">=</span><span class="bp">False</span>
    
<span class="n">model1_f</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s">'categorical_crossentropy'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s">'adam'</span><span class="p">,</span><span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span>

<span class="n">model1_f</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_f</span><span class="p">,</span> <span class="n">Y_train_f</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<p>The main advantages of transfer learning are related to computational efficiency and small datasets:</p>
<ul>
  <li><strong>Computational Efficiency</strong>: By freezing most of the layers in the network, we have fewer trainable parameters.  This allows us to adapt a network to a new problem with much less computation than it would take to train the entire network from scratch.  This computational advantage may not be apparent here since we are dealing with a relatively small network and small dataset, but can become significant with larger networks and datasets.</li>
  <li><strong>Small Datasets</strong>: Training a very large network on a small dataset runs the risk of significant overfitting (learning the data).  Transfer learning allows us to “borrow” knowledge from much larger datasets and focusing the learning on the classification task.</li>
</ul>

<h2 id="-your-turn--11"><span style="color:Green"> Your turn: </span></h2>
<p>How well does our new transfer learning model <code class="language-plaintext highlighter-rouge">model1_f</code> perform on the Fashion-MNIST data?</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>

<p>You have probably found that the network does not perform as well on the Fashion-MNIST dataset as it did on MNIST.  If you trained the full 2-layer network from scratch (as we did for MNIST), you would achieve approximately 89% test accuracy.</p>

<h2 id="-your-turn--12"><span style="color:Green"> Your turn: </span></h2>
<p>How well does our new transfer learning model <code class="language-plaintext highlighter-rouge">model1_f</code> perform on the original MNIST data?</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>

<h2 id="-your-turn--13"><span style="color:Green"> Your turn: </span></h2>
<p>How does the transfer learning work if you freeze fewer layers?</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>

<h1 id="section-6-saving-trained-models">Section 6: Saving Trained Models</h1>
<p>We can save a trained model so that we don’t have to go through the bother of training it again later.  The following instructions save the model in a binary file in HDF5 (Hierarchical Data Format).  The use of these commands assume that you have <code class="language-plaintext highlighter-rouge">h5py</code> (the python interface to HDF5 format) installed.  For at least the Linux version of Anaconda 3.7, it appears that <code class="language-plaintext highlighter-rouge">h5py</code> was included.  If it does not appear that you have <code class="language-plaintext highlighter-rouge">h5py</code> installed, you can run the following command from your computer’s terminal</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>conda install h5py
</code></pre></div></div>
<p>The successful installation of <code class="language-plaintext highlighter-rouge">h5py</code>, however, requires that the HDF5 libraries to be installed on your computer.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model1</span><span class="p">.</span><span class="n">save</span><span class="p">(</span><span class="s">'model1.h5'</span><span class="p">)</span>
<span class="n">model1_f</span><span class="p">.</span><span class="n">save</span><span class="p">(</span><span class="s">'model1_f.h5'</span><span class="p">)</span>
</code></pre></div></div>

<p>This will save a binary file named <code class="language-plaintext highlighter-rouge">model1.h5</code> to the same directory as this notebook.  You can load this file and pick up right where we left off.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model1</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="s">'model1.h5'</span><span class="p">)</span>
<span class="n">model1_f</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="s">'model1_f.h5'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>


        
      </section>

      <footer class="page__meta">
        
        


        
      </footer>

      

      

    </div>

    
  </article>

  
  
</div>
    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><form onsubmit="return googleCustomSearchExecute();" id="cse-search-box-form-id">
    <input type="search" id="cse-search-input-box-id" aria-placeholder="Enter your search term..." class="search-input" tabindex="-1" placeholder="Enter your search term..." />
    </form>
    <div id="results" class="results">
        <gcse:searchresults-only></gcse:searchresults-only>
    </div></div>

      </div>
    
    
    <div class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->

        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    
    
      <li><a href="https://twitter.com/isugif"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
    
    
    
      <li><a href="https://github.com/https://github.com/isugenomics"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
    
    
    
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2024 Geospatial Workbook</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>
  <script src="https://use.fontawesome.com/releases/v5.0.13/js/all.js"></script>


<script>
  (function () {
    var cx = '009853197685285203469:nsvri1pa88d';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();

  function googleCustomSearchExecute() {
    var input = document.getElementById('cse-search-input-box-id');
    var element = google.search.cse.element.getElement('searchresults-only0');
    if (input.value == '') {
      element.clearAllResults();
    } else {
      element.execute(input.value);
    }
    return false;
  }

  
</script>




<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" defer
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>




  </body>
</html>
