<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.11.2 by Michael Rose
  Copyright 2013-2018 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE.txt
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Premeeting - Geospatial Workbook</title>
<meta name="description" content="Tutorial on Informatics for Geospatial Information">


  <meta name="author" content="Kerrie Geil">


<meta property="og:type" content="website">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Geospatial Workbook">
<meta property="og:title" content="Premeeting">
<meta property="og:url" content="http://localhost:4000/IntroductionToImageAnalysis/Tutorial1_Image_Processing_Essentials.html">




  <meta property="og:image" content="http://localhost:4000/assets/images/margaret-weir-GZyjbLNOaFg-unsplash_dark.jpg">



  <meta name="twitter:site" content="@isugif">
  <meta name="twitter:title" content="Premeeting">
  <meta name="twitter:description" content="Tutorial on Informatics for Geospatial Information">
  <meta name="twitter:url" content="http://localhost:4000/IntroductionToImageAnalysis/Tutorial1_Image_Processing_Essentials.html">

  
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:image" content="http://localhost:4000/assets/images/margaret-weir-GZyjbLNOaFg-unsplash_dark.jpg">
  

  
    <meta name="twitter:creator" content="@someone">
  







  

  


<link rel="canonical" href="http://localhost:4000/IntroductionToImageAnalysis/Tutorial1_Image_Processing_Essentials.html">







  <script type="application/ld+json">
    {
      "@context": "http://schema.org",
      "@type": "Person",
      "name": "",
      "url": "http://localhost:4000",
      "sameAs": null
    }
  </script>







<!-- end _includes/seo.html -->


<link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Geospatial Workbook Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">

<!--[if lte IE 9]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->


    <!-- start custom head snippets -->

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-E6BZVYF8ZY"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-E6BZVYF8ZY');
</script>

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single">

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    <div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <a class="site-title" href="/">Geospatial Workbook</a>
        <ul class="visible-links">
          
            
            <li class="masthead__menu-item">
              <a href="http://localhost:4000/about.html" >About</a>
            </li>
          
            
            <li class="masthead__menu-item">
              <a href="http://localhost:4000/list.html" >Index</a>
            </li>
          
            
            <li class="masthead__menu-item">
              <a href="http://localhost:4000/glossary.html" >Glossary</a>
            </li>
          
            
            <li class="masthead__menu-item">
              <a href="http://localhost:4000/people.html" >People</a>
            </li>
          
            
            <li class="masthead__menu-item">
              <a href="http://localhost:4000/contributing.html" >Contribute</a>
            </li>
          
        </ul>
        
        <button class="search__toggle" type="button">
          <svg class="icon" width="16" height="16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 15.99 16">
            <path d="M15.5,13.12L13.19,10.8a1.69,1.69,0,0,0-1.28-.55l-0.06-.06A6.5,6.5,0,0,0,5.77,0,6.5,6.5,0,0,0,2.46,11.59a6.47,6.47,0,0,0,7.74.26l0.05,0.05a1.65,1.65,0,0,0,.5,1.24l2.38,2.38A1.68,1.68,0,0,0,15.5,13.12ZM6.4,2A4.41,4.41,0,1,1,2,6.4,4.43,4.43,0,0,1,6.4,2Z" transform="translate(-.01)"></path>
          </svg>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle Menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      
  











<div class="page__hero--overlay"
  style="background-color: 444444; background-image: url('/assets/images/margaret-weir-GZyjbLNOaFg-unsplash_dark.jpg');"
>
  
    <div class="wrapper">
      <h1 id="page-title" class="page__title" itemprop="headline">
        
          Premeeting

        
      </h1>
      
      
      
    </div>
  
  
</div>





<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="http://schema.org/Person">

  
    <div class="author__avatar">
      

      
        <img src="/assets/images/people/KerrieGeil.png" alt="Kerrie Geil" itemprop="image">
      
    </div>
  

  <div class="author__content">
    
      <h3 class="author__name" itemprop="name">Kerrie Geil</h3>
    
    
      <p class="author__bio" itemprop="description">
        Kerrie is an ARS SCINet postdoc in the research group of Dr. Deb Peters in Las Cruces, NM. Her M.S. and Ph.D. degrees are in Atmospheric Sciences and her research background is in climate modeling.
      </p>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      

      

      
        <li>
          <a href="mailto:mailto:someone@iastate.edu">
            <meta itemprop="email" content="mailto:someone@iastate.edu" />
            <i class="fas fa-fw fa-envelope-square" aria-hidden="true"></i> Email
          </a>
        </li>
      

      

      
        <li>
          <a href="https://twitter.com/someone" itemprop="sameAs">
            <i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter
          </a>
        </li>
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

<!-- Create a 2nd author for tutorials -->



<div itemscope itemtype="http://schema.org/Person">

  

  <div class="author__content">
    
      <h3 class="author__name" itemprop="name"></h3>
    
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
  </div>


  <article class="page" itemscope itemtype="http://schema.org/CreativeWork">
    <meta itemprop="headline" content="Premeeting">
    
    
    

    <div class="page__inner-wrap">
      

      <section class="page__content" itemprop="text">
        
        <h1 id="tutorial-1-image-processing-fundamentals">Tutorial 1: Image Processing Fundamentals</h1>
<h2 id="laura-e-boucheron-electrical--computer-engineering-nmsu">Laura E. Boucheron, Electrical &amp; Computer Engineering, NMSU</h2>
<h3 id="october-2020">October 2020</h3>
<p>Copyright (C) 2020  Laura E. Boucheron</p>

<p>This information is free; you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation; either version 3 of the License, or (at your option) any later version.</p>

<p>This work is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.</p>

<p>You should have received a copy of the GNU General Public License along with this work in a file <code class="language-plaintext highlighter-rouge">COPYING.TXT</code>; if not, see <a href="https://www.gnu.org/licenses/">https://www.gnu.org/licenses/</a>.</p>

<h2 id="overview">Overview</h2>
<p>In this tutorial, we present a brief overview of image processing concepts necessary to understand machine learning and deep learning.  Completion of this tutorial should give participants the basic background and terminology necessary for an understanding of the basics of image processing and the common manipulations of images used for machine learning and deep learning.</p>

<p>This tutorial contains 5 sections:</p>
<ul>
  <li><strong>Section 0: Preliminaries</strong>: some notes on using this notebook and how to download the two images that we will use for this tutorial</li>
  <li><strong>Section 1: Working with Grayscale Images</strong>: how to read, query characteristics, intepret, and display grayscale images</li>
  <li><strong>Section 2: Working with Color Images</strong>: how to read, query characteristics, interpret, and display color images</li>
  <li><strong>Section 3: Transforming Images</strong>: how to convert between grayscale and color images, how to rescale the spatial dimensions of an image through cropping and resizing, and other geometric transformations</li>
  <li><strong>Section 4: Filtering Images</strong>: the basics of filtering images through convolution with a filter kernel</li>
</ul>

<p>There are subsections with the heading <strong><span style="color:Green"> Your turn: </span></strong> throughout this tutorial in which you will be asked to apply what you have learned.</p>

<h1 id="section-0-preliminaries">Section 0: Preliminaries</h1>
<h2 id="section-01-a-note-on-jupyter-notebooks">Section 0.1 A Note on Jupyter Notebooks</h2>

<p>There are two main types of cells in this notebook: code and markdown (text).  You can add a new cell with the plus sign in the menu bar above and you can change the type of cell with the dropdown menu in the menu bar above.  As you complete this tutorial, you may wish to add additional code cells to try out your own code and markdown cells to add your own comments or notes.</p>

<p>Markdown cells can be augmented with a number of text formatting features, including</p>
<ul>
  <li>bulleted</li>
  <li>lists</li>
</ul>

<p>embedded $\LaTeX$, monotype specification of <code class="language-plaintext highlighter-rouge">code syntax</code>, <strong>bold font</strong>, and <em>italic font</em>.  There are many other features of markdown cells–see the jupyter documentation for more information.</p>

<p>You can edit a cell by double clicking on it.  If you double click on this cell, you can see how to implement the various formatting referenced above.  Code cells can be run and markdown cells can be formatted using Shift+Enter or by selecting the Run button in the toolbar above.</p>

<p>Once you have completed (all or part) of this notebook, you can share your results with colleagues by sending them the <code class="language-plaintext highlighter-rouge">.ipynb</code> file.  Your colleagues can then open the file and will see your markdown and code cells as well as any results that were printed or displayed at the time you saved the notebook.  If you prefer to send a notebook without results displayed (like this notebook appeared when you downloaded it), you can select (“Restart &amp; Clear Output”) from the Kernel menu above.  You can also export this notebook in a non-executable form, e.g., <code class="language-plaintext highlighter-rouge">.pdf</code> through the File, Download As or File, Export Notebook as menu.</p>

<h2 id="section-02-downloading-images">Section 0.2 Downloading Images</h2>
<p>First, we need to download images to work with in this tutorial.  Download <code class="language-plaintext highlighter-rouge">cameraman.png</code> and <code class="language-plaintext highlighter-rouge">peppers.png</code> from the DL workshop website (https://kerriegeil.github.io/NMSU-USDA-ARS-AI-Workshops/) and save them to the same directory as this notebook.  Both of these images are common example images used in image processing and are often included as part of the distribution of image processing toolboxes.</p>

<h2 id="section-03a-import-necessary-libraries-for-users-using-a-local-machine">Section 0.3a Import Necessary Libraries (For users using a local machine)</h2>
<p>First, we import necessary libraries:</p>
<ul>
  <li>We <code class="language-plaintext highlighter-rouge">import numpy as np</code> mostly out of habit since <code class="language-plaintext highlighter-rouge">numpy</code> contains many common mathematical and scientific functions</li>
  <li>We import the <code class="language-plaintext highlighter-rouge">matplotlib</code> plotting library which provides many common plotting routines (including image visualization).  There are other plotting libraries, but <code class="language-plaintext highlighter-rouge">matplotlib</code> was designed to mimic much of the functionality of Matlab plotting and is thus very nice for those of us who transitioned from Matlab to python.</li>
  <li>We specify that plots should occur inline in the notebook (rather than in external figure windows).  This is very convenient if you want a single document of your code and results.</li>
  <li>We import the <code class="language-plaintext highlighter-rouge">imageio</code> library which provides functions to read common image formats.  We use imageio here since it returns images as an array.  We note that there are other powerful image libraries, including <code class="language-plaintext highlighter-rouge">PIL</code> / <code class="language-plaintext highlighter-rouge">pillow</code> which is used by the very nice <code class="language-plaintext highlighter-rouge">pandas</code> library for data manipulation.  We work with images as simple <code class="language-plaintext highlighter-rouge">nparrays</code> here since that best illustrates the basic image processing concepts.</li>
  <li>We import two packages from scikit-image (<code class="language-plaintext highlighter-rouge">skimage</code>) which provides image manipulation functions</li>
  <li>We import the <code class="language-plaintext highlighter-rouge">ndimage</code> package from <code class="language-plaintext highlighter-rouge">scipy</code> which provides image filtering functions</li>
</ul>

<p>It would be best to run this next cell before the workshop starts to make sure you have all the necessary packages installed on your machine.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span> 
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="kn">import</span> <span class="nn">imageio</span>
<span class="kn">import</span> <span class="nn">skimage.color</span>
<span class="kn">import</span> <span class="nn">skimage.transform</span>
<span class="kn">import</span> <span class="nn">scipy.ndimage</span> <span class="k">as</span> <span class="n">ndimage</span>
</code></pre></div></div>

<h2 id="section-03b-build-the-conda-environment-for-users-using-the-ars-hpc-ceres-with-jupyterlab">Section 0.3b Build the Conda Environment (For users using the ARS HPC Ceres with JupyterLab)</h2>
<p>Open a terminal from inside JupyterLab (File &gt; New &gt; Terminal) and type the following commands</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>source activate
wget https://kerriegeil.github.io/NMSU-USDA-ARS-AI-Workshops/aiworkshop.yml
conda env create --prefix /project/your_project_name/envs/aiworkshop -f aiworkshop.yml
</code></pre></div></div>

<p>This will build the environment in one of your project directories. It may take 5 minutes to build the Conda environment.</p>

<p>See https://kerriegeil.github.io/NMSU-USDA-ARS-AI-Workshops/setup/ for more information.</p>

<p>When the environment finishes building, select this environment as your kernel in your Jupyter Notebook (click top right corner where you see Python 3, select your new kernel from the dropdown menu, click select)</p>

<p>You will want to do this BEFORE the workshop starts.</p>

<h1 id="section-1-working-with-grayscale-images">Section 1: Working with Grayscale Images</h1>

<h2 id="11-reading-in-the-image">1.1 Reading in the image</h2>
<p>We can read in the images using the <code class="language-plaintext highlighter-rouge">imageio.imread</code> command.  We explicitly cast the image as an np array as this will give us access to some helpful characteristics of the image.  We begin with the grayscale <code class="language-plaintext highlighter-rouge">cameraman.png</code> image.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">I_camera</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">imageio</span><span class="p">.</span><span class="n">imread</span><span class="p">(</span><span class="s">'data/cameraman.png'</span><span class="p">))</span>
</code></pre></div></div>

<h2 id="12-displaying-the-image">1.2 Displaying the image</h2>
<p>Let’s display this image.  We use the <code class="language-plaintext highlighter-rouge">matplotlib</code> <code class="language-plaintext highlighter-rouge">imshow</code> command.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">()</span>                      <span class="c1"># open a new figure window
</span><span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">I_camera</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s">'gray'</span><span class="p">)</span> <span class="c1"># visualize the I_camera image with a grayscale colormap
</span><span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>                        <span class="c1"># show the plot
</span></code></pre></div></div>

<p><img src="Tutorial1_Image_Processing_Essentials_files/Tutorial1_Image_Processing_Essentials_10_0.png" alt="png" /></p>

<h3 id="a-note-about-coordinate-conventions">A note about coordinate conventions</h3>

<p>By default, axis labels are included which demarcate pixel counts.  You may notice that the origin of an image is interpreted as the <strong>upper left</strong> corner and not the lower left corner as you might have expected.  This is a consequence of the fact that we use standard linear algebra style indexing for images where pixel $(n,m)$ is indexed in row, column order.  For those of you who might be particularly concerned, this coordinate system still describes a right-handed system.</p>

<p>This coordinate system can cause issues later on if you accidentally swap indices.  You might think you are looking in the upper right but are actually looking in the lower left.  You might think you are traversing left to right and are actually traversing up to down.</p>

<h2 id="13-changing-display-parameters">1.3 Changing display parameters</h2>
<p>There are various choices in display that you can make, including:</p>
<ul>
  <li>scaling the figure window using <code class="language-plaintext highlighter-rouge">figsize=(x,y)</code> within the <code class="language-plaintext highlighter-rouge">plt.figure()</code> command.  In this, <code class="language-plaintext highlighter-rouge">x</code> and <code class="language-plaintext highlighter-rouge">y</code> are arbitrary units.  A reasonable choice for these units will depend on your computer’s display parameters.</li>
  <li>scaling the size of the text labels with the command <code class="language-plaintext highlighter-rouge">plt.rcParams.update({'font.size': f})</code> where <code class="language-plaintext highlighter-rouge">f</code> is the font size you desire in units of pt, e.g., 20.  You need to run this only once to update the font size parameters, after which all subsequent figure windows will use this new font size</li>
  <li>removing the axis labels with the command <code class="language-plaintext highlighter-rouge">plt.axis('off')</code></li>
  <li>adding axis labels or a title to your plot, e.g., <code class="language-plaintext highlighter-rouge">plt.xlabel('flamingos')</code>, <code class="language-plaintext highlighter-rouge">plt.ylabel('emus')</code>, <code class="language-plaintext highlighter-rouge">plt.title('Emus versus flamingos')</code>.  Note that if you have turned the axes off, your titles will not show up.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="n">rcParams</span><span class="p">.</span><span class="n">update</span><span class="p">({</span><span class="s">'font.size'</span><span class="p">:</span> <span class="mi">20</span><span class="p">})</span>
<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">20</span><span class="p">))</span>                <span class="c1"># open a new figure window of size 20x20 (artbitrary units)
</span><span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">I_camera</span><span class="p">,</span><span class="n">cmap</span><span class="o">=</span><span class="s">'gray'</span><span class="p">)</span>           <span class="c1"># visualize the I_camera image with a grayscale colormap
</span><span class="n">plt</span><span class="p">.</span><span class="n">axis</span><span class="p">(</span><span class="s">'off'</span><span class="p">)</span>                            <span class="c1"># turn off the axis labels
</span><span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'flamingos'</span><span class="p">)</span>                    <span class="c1"># provide a label for the x axis
</span><span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'emus'</span><span class="p">)</span>                         <span class="c1"># provide a label for the y axis
</span><span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Emus versus flamingos'</span><span class="p">)</span>         <span class="c1"># provide a title for the plot
</span><span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>                                 <span class="c1"># show the plot
</span></code></pre></div></div>

<p><img src="Tutorial1_Image_Processing_Essentials_files/Tutorial1_Image_Processing_Essentials_13_0.png" alt="png" /></p>

<h2 id="-your-turn--"><span style="color:Green"> Your turn:  </span></h2>
<p>Choose a figure size so that the image fills the width of your notebook and provide a descriptive title to your image.  You may also choose to label your axes or not, per your preference.  For what it’s worth, image processing people don’t tend to display axis labels.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>

<h2 id="14-printing-image-characteristics">1.4 Printing Image Characteristics</h2>
<p>We can check on important characteristics of <code class="language-plaintext highlighter-rouge">I_camera</code> using the <code class="language-plaintext highlighter-rouge">%whos</code> magic ipython command.  Note–within some environments, including jupyter notebooks, you can drop the <code class="language-plaintext highlighter-rouge">%</code> althought it’s probably best practice to get used to including it.</p>

<h3 id="141-using-the-whos-command">1.4.1 Using the %whos command</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%</span><span class="n">whos</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Variable   Type       Data/Info
-------------------------------
I_camera   ndarray    256x256: 65536 elems, type `uint8`, 65536 bytes
imageio    module     &lt;module 'imageio' from '/&lt;...&gt;ges/imageio/__init__.py'&gt;
ndimage    module     &lt;module 'scipy.ndimage' f&lt;...&gt;ipy/ndimage/__init__.py'&gt;
np         module     &lt;module 'numpy' from '/Us&lt;...&gt;kages/numpy/__init__.py'&gt;
plt        module     &lt;module 'matplotlib.pyplo&lt;...&gt;es/matplotlib/pyplot.py'&gt;
skimage    module     &lt;module 'skimage' from '/&lt;...&gt;ges/skimage/__init__.py'&gt;
</code></pre></div></div>

<h3 id="a-note-on-common-image-variable-types">A note on common image variable types</h3>
<p>We see that <code class="language-plaintext highlighter-rouge">I_camera</code> is an <code class="language-plaintext highlighter-rouge">ndarray</code> of size $256\times256$ pixels and of variable type <code class="language-plaintext highlighter-rouge">uint8</code> (unsigned 8-bit integer).  Remember that computers store data natively in binary (base-2) format.  The <code class="language-plaintext highlighter-rouge">uint8</code> variable type means we have 8 bits (the <code class="language-plaintext highlighter-rouge">'8'</code> in <code class="language-plaintext highlighter-rouge">uint8</code>) to represent a range of positive (the <code class="language-plaintext highlighter-rouge">'u'</code> in <code class="language-plaintext highlighter-rouge">uint8</code>) integers (the <code class="language-plaintext highlighter-rouge">'int'</code> in <code class="language-plaintext highlighter-rouge">uint8</code>).  It is very common that image pixels are represented as <code class="language-plaintext highlighter-rouge">uint8</code> variables, which also indicates that the pixels are within the range $[0,255]$ (since $2^0-1=0$ and $2^8-1=255$).</p>

<p>Since there is only one color channel, i.e., <code class="language-plaintext highlighter-rouge">I_camera</code> is a 2D array $\in\mathbb{R}^{N\times M}$ rather than a 3D array $\in\mathbb{R}^{N\times M\times C}$ (more on that later), we also know that this is a grayscale image.</p>

<h3 id="142-printing-the-max-and-min-values-of-an-image">1.4.2 Printing the max and min values of an image</h3>
<p>We can check for the actual maximum and minimum values of the image.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="s">'The minimum value of I_camera is '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">I_camera</span><span class="p">.</span><span class="nb">min</span><span class="p">()))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'The maximum value of I_camera is '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">I_camera</span><span class="p">.</span><span class="nb">max</span><span class="p">()))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>The minimum value of I_camera is 7
The maximum value of I_camera is 253
</code></pre></div></div>

<h3 id="a-note-on-image-intensity-conventions">A note on image intensity conventions</h3>
<p>We note that this <code class="language-plaintext highlighter-rouge">I_camera</code> image spans the range $[7,253]$.  In grayscale images, it is common interpretation that <strong>darker pixels have smaller intensity values and lighter pixels have larger intensity values</strong>.</p>

<h3 id="143-printing-a-portion-of-the-image">1.4.3 Printing a portion of the image</h3>
<p>It is also important to remember that the computer “sees” only an array of values.  To reinforce this, we can “look” at what the computer “sees” in a portion of the image.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">I_camera</span><span class="p">[</span><span class="mi">100</span><span class="p">:</span><span class="mi">110</span><span class="p">,</span><span class="mi">100</span><span class="p">:</span><span class="mi">110</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[[  9  11  13  11  11  11  16 106 178  68]
 [ 12  12  12  11  12  11  69 181  62  15]
 [ 13  12  12  11  12  82 168  60  14  13]
 [ 11  10   9  10  69 182  67  14  12  14]
 [ 10  10  10  71 200  81  15  12  14  14]
 [ 12  12  58 204  91  17  12  14  14  17]
 [ 11  46 201 106  18  14  16  15  16  16]
 [ 34 185 122  23  10  14  17  16  13  13]
 [186 135  30  11   9   9  10  10   9  10]
 [154  33  11  13  12   9   9   9   9  11]]
</code></pre></div></div>

<h2 id="-your-turn---1"><span style="color:Green"> Your turn:  </span></h2>
<p>What does this printout tell us about the structure in that part of the image?</p>

<h3 id="144-visualizing-a-portion-of-an-image">1.4.4 Visualizing a portion of an image</h3>
<p>We could use <code class="language-plaintext highlighter-rouge">plt.imshow</code> to display that small portion of the image.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">I_camera</span><span class="p">[</span><span class="mi">100</span><span class="p">:</span><span class="mi">110</span><span class="p">,</span><span class="mi">100</span><span class="p">:</span><span class="mi">110</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s">'gray'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">axis</span><span class="p">(</span><span class="s">'off'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Cameraman portion, grayscale'</span><span class="p">)</span> 
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span> 
</code></pre></div></div>

<p><img src="Tutorial1_Image_Processing_Essentials_files/Tutorial1_Image_Processing_Essentials_28_0.png" alt="png" /></p>

<h2 id="-your-turn---2"><span style="color:Green"> Your turn:  </span></h2>
<p>Does this display of the image verify your interpretation from the printout of the pixel values?</p>

<h3 id="145-another-visualization-of-a-portion-of-an-image">1.4.5 Another visualization of a portion of an image</h3>
<p>Here, we maintain the display of the whole image, and plot a yellow box around the area that we’ve been discussing.  This can be a helpful visualization since it maintains the context of the box.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">20</span><span class="p">))</span> 
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">I_camera</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s">'gray'</span><span class="p">)</span> 
<span class="n">plt</span><span class="p">.</span><span class="n">axis</span><span class="p">(</span><span class="s">'off'</span><span class="p">)</span> 
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Cameraman, grayscale'</span><span class="p">)</span> 
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">100</span><span class="p">,</span><span class="mi">100</span><span class="p">],[</span><span class="mi">100</span><span class="p">,</span><span class="mi">110</span><span class="p">],</span> <span class="s">'y-'</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">110</span><span class="p">,</span><span class="mi">110</span><span class="p">],[</span><span class="mi">100</span><span class="p">,</span><span class="mi">110</span><span class="p">],</span> <span class="s">'y-'</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">100</span><span class="p">,</span><span class="mi">110</span><span class="p">],[</span><span class="mi">100</span><span class="p">,</span><span class="mi">100</span><span class="p">],</span> <span class="s">'y-'</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">100</span><span class="p">,</span><span class="mi">110</span><span class="p">],[</span><span class="mi">110</span><span class="p">,</span><span class="mi">110</span><span class="p">],</span> <span class="s">'y-'</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span> 
</code></pre></div></div>

<p><img src="Tutorial1_Image_Processing_Essentials_files/Tutorial1_Image_Processing_Essentials_32_0.png" alt="png" /></p>

<h2 id="-your-turn---3"><span style="color:Green"> Your turn:  </span></h2>
<p>What happens if you plot the image using <code class="language-plaintext highlighter-rouge">imshow</code> but “forget” to specify the colormap as <code class="language-plaintext highlighter-rouge">gray</code>?</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>

<h3 id="a-note-on-colormaps">A note on colormaps</h3>
<p>You should have found that the grayscale image now appears colored.  How can that be if the image is a single channel, i.e., grayscale image?  In this case, python is applying the default colormap to the intensities.  In this default colormap, dark pixels appear dark blue, medium intensity pixels appear green or blue, and light pixels appear yellow. (Your computer may use a different default colormap in which case the colors noted above may not be correct).</p>

<p>You can choose any number of colormaps (see https://matplotlib.org/3.1.0/tutorials/colors/colormaps.html for a comprehensive list and examples).</p>

<p>There are also many other options for <code class="language-plaintext highlighter-rouge">plt.imshow</code>, see <code class="language-plaintext highlighter-rouge">help(plt.imshow)</code> for more details.</p>

<h1 id="section-2-working-with-color-images">Section 2: Working with Color Images</h1>

<h2 id="21-reading-in-and-displaying-the-image">2.1 Reading in and displaying the image</h2>
<p>Now, we turn to the color <code class="language-plaintext highlighter-rouge">peppers.png</code> image.  We use the same command to read in the image and the same basic commands to visualize the image.  The only difference here is that we allow python to choose a default colormap for this color image.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">I_pepper</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">imageio</span><span class="p">.</span><span class="n">imread</span><span class="p">(</span><span class="s">'data/peppers.png'</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">20</span><span class="p">))</span> <span class="c1"># open a new figure window of size 20x20 (artbitrary units)
</span><span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">I_pepper</span><span class="p">)</span> <span class="c1"># visualize the I_pepper image with a default colormap
</span><span class="n">plt</span><span class="p">.</span><span class="n">axis</span><span class="p">(</span><span class="s">'off'</span><span class="p">)</span> <span class="c1"># turn off the axis labels
</span><span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Peppers, RGB'</span><span class="p">)</span> <span class="c1"># provide a title for the plot
</span><span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span> <span class="c1"># show the plot
</span></code></pre></div></div>

<p><img src="Tutorial1_Image_Processing_Essentials_files/Tutorial1_Image_Processing_Essentials_38_0.png" alt="png" /></p>

<h2 id="22-printing-image-characteristics">2.2 Printing image characteristics</h2>
<p>We can check on important characteristics of <code class="language-plaintext highlighter-rouge">I_pepper</code>.</p>

<h3 id="221-the-whos-command">2.2.1 The %whos command</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%</span><span class="n">whos</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Variable   Type       Data/Info
-------------------------------
I_camera   ndarray    256x256: 65536 elems, type `uint8`, 65536 bytes
I_pepper   ndarray    384x512x3: 589824 elems, type `uint8`, 589824 bytes (576.0 kb)
imageio    module     &lt;module 'imageio' from '/&lt;...&gt;ges/imageio/__init__.py'&gt;
ndimage    module     &lt;module 'scipy.ndimage' f&lt;...&gt;ipy/ndimage/__init__.py'&gt;
np         module     &lt;module 'numpy' from '/Us&lt;...&gt;kages/numpy/__init__.py'&gt;
plt        module     &lt;module 'matplotlib.pyplo&lt;...&gt;es/matplotlib/pyplot.py'&gt;
skimage    module     &lt;module 'skimage' from '/&lt;...&gt;ges/skimage/__init__.py'&gt;
</code></pre></div></div>

<h3 id="a-note-on-color-channel-conventions">A note on color channel conventions</h3>
<p>We see that <code class="language-plaintext highlighter-rouge">I_pepper</code> is an <code class="language-plaintext highlighter-rouge">ndarray</code> of size $384\times512\times 3$ pixels and of variable type <code class="language-plaintext highlighter-rouge">uint8</code> (unsigned 8-bit integer).  We thus have a 3-channel image where the three channels are assumed to be a red (R), green (G), and blue (B) channel, i.e., an RGB image.  <strong>By convention, the first channel is assumed to be R, the second G, and the third B.</strong></p>

<p>Again, we note that image pixels are represented as <code class="language-plaintext highlighter-rouge">uint8</code> variables.  In this case, however, each pixel is associated with 3 <code class="language-plaintext highlighter-rouge">uint8</code> values, resulting in $2^8 2^8 2^8=2^{24}=16,777,216$ unique colors.  <strong>Colors which have equal contribution from R, G, and B are grayscale.</strong></p>

<h3 id="222-max-and-min-values">2.2.2 Max and min values</h3>
<p>We can check for the actual maximum and minimum values of the image or of the R, G, or B channels.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="s">'Max and min values of the image:'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'    Min: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">I_pepper</span><span class="p">.</span><span class="nb">min</span><span class="p">()))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'    Max: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">I_pepper</span><span class="p">.</span><span class="nb">max</span><span class="p">()))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Max and min values of the red channel:'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'    Min: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">I_pepper</span><span class="p">[:,:,</span><span class="mi">0</span><span class="p">].</span><span class="nb">min</span><span class="p">()))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'    Max: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">I_pepper</span><span class="p">[:,:,</span><span class="mi">0</span><span class="p">].</span><span class="nb">max</span><span class="p">()))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Max and min values of the green channel:'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'    Min: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">I_pepper</span><span class="p">[:,:,</span><span class="mi">1</span><span class="p">].</span><span class="nb">min</span><span class="p">()))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'    Max: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">I_pepper</span><span class="p">[:,:,</span><span class="mi">1</span><span class="p">].</span><span class="nb">max</span><span class="p">()))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Max and min values of the blue channel:'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'    Min: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">I_pepper</span><span class="p">[:,:,</span><span class="mi">2</span><span class="p">].</span><span class="nb">min</span><span class="p">()))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'    Max: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">I_pepper</span><span class="p">[:,:,</span><span class="mi">2</span><span class="p">].</span><span class="nb">max</span><span class="p">()))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Max and min values of the image:
    Min: 0
    Max: 255
Max and min values of the red channel:
    Min: 5
    Max: 255
Max and min values of the green channel:
    Min: 1
    Max: 255
Max and min values of the blue channel:
    Min: 0
    Max: 255
</code></pre></div></div>

<h3 id="a-note-on-intensity-conventions-in-color-images">A note on intensity conventions in color images</h3>
<p>We note that this <code class="language-plaintext highlighter-rouge">I_pepper</code> image spans the range $[5,255]$ in R, $[1,255]$ in G, and $[0,255]$ in B.  We also note that when we didn’t specify a color channel, python returned the max and min across the three color channels.</p>

<p>Extending the interpretation of a single channel image in which darker pixels have smaller intensity values and lighter pixels have larger intensity values, a color is defined as the contribution of R, G, and B, where larger intensities in those channels correspond to larger contribution from those colors.</p>

<h3 id="223-printing-a-portion-of-the-image">2.2.3 Printing a portion of the image</h3>
<p>Since we have three color channels in this color image, we print out each of the color channels separately.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="s">'Red:'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">I_pepper</span><span class="p">[</span><span class="mi">100</span><span class="p">:</span><span class="mi">110</span><span class="p">,</span><span class="mi">100</span><span class="p">:</span><span class="mi">110</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Green'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">I_pepper</span><span class="p">[</span><span class="mi">100</span><span class="p">:</span><span class="mi">110</span><span class="p">,</span><span class="mi">100</span><span class="p">:</span><span class="mi">110</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Blue'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">I_pepper</span><span class="p">[</span><span class="mi">100</span><span class="p">:</span><span class="mi">110</span><span class="p">,</span><span class="mi">100</span><span class="p">:</span><span class="mi">110</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Red:
[[ 62  60  60  61  61  61  60  57  61  67]
 [ 64  61  59  60  59  56  55  56  59  64]
 [ 62  62  61  59  56  52  62  73  85  92]
 [ 64  63  61  66  67  77  92 101 108 112]
 [ 63  60  59  71  86  96 102 109 110 114]
 [ 71  67  71  84  96 100 106 115 119 120]
 [107 104 100  99 104 109 112 123 126 127]
 [118 116 116 113 114 118 113 117 129 135]
 [120 119 117 110 105 108 110 107 114 127]
 [129 129 123 121 115 115 111 105 103 105]]
Green
[[ 34  35  36  36  33  32  32  34  34  38]
 [ 37  36  36  36  33  33  33  33  34  41]
 [ 35  36  37  39  38  37  44  58  72  85]
 [ 36  36  35  38  47  69  87  99 108 114]
 [ 39  37  39  57  82  97 103 107 113 117]
 [ 55  49  60  85  96 105 110 114 119 122]
 [104 100  99 101 103 108 116 119 121 124]
 [115 113 114 114 114 115 114 116 125 133]
 [116 112 110 109 105 106 107 108 111 123]
 [123 124 120 117 113 111 108 104 100  99]]
Blue
[[60 63 64 61 58 56 55 55 61 66]
 [66 63 61 60 60 59 56 57 55 55]
 [60 63 67 62 58 56 50 46 40 34]
 [61 61 64 60 50 44 29 21 16 11]
 [66 60 55 43 36 28 16 10 15 21]
 [49 48 37 26 22 19 13  6 10 16]
 [23 23 21 20 19 18 14  9 10  6]
 [24 21 23 24 24 30 23 17 19 22]
 [32 32 31 28 23 26 27 22 15 22]
 [32 26 15 11 12  7  8 15 12 14]]
</code></pre></div></div>

<h2 id="-your-turn---4"><span style="color:Green"> Your turn:  </span></h2>
<p>What does this printout tell us about the structure in that part of the image?  It can be a bit harder to interpret this sort of printout for a color image since we must keep track of multiple color channels simultaneously.  There are other color spaces in which color interpretation are easier (e.g., HSV), but that is outside the scope of this tutorial.</p>

<h2 id="-your-turn---5"><span style="color:Green"> Your turn:  </span></h2>
<p>Visualize where in the image we are looking by overlaying a box on the image visualization.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>

<h1 id="section-3-transforming-images">Section 3: Transforming Images</h1>
<p>We will find that many deep learning methods are very particular about the size of input images.  This particularity about size extends across all three dimensions–the two spatial dimensions and the color dimension.  As such, it is useful to learn a couple of common methods to rescale images in all three dimensions. Here, we will learn how to <strong>convert between RGB and grayscale</strong>, how to <strong>crop</strong> images, how to <strong>resize</strong> images.</p>

<h2 id="31-color-to-grayscale">3.1 Color to Grayscale</h2>
<p>We can convert a color image to a grayscale image using a standard command included in Scikit-Image.  We can use the <code class="language-plaintext highlighter-rouge">skimage.color.rgb2gray</code> function to convert the RGB image <code class="language-plaintext highlighter-rouge">I_pepper</code> to a grayscale image.  The <code class="language-plaintext highlighter-rouge">skimage.color.rgb2gray</code> function applies a weighted averaging of the three color channels to yield a grayscale image.  As a note, there is no single accepted weighting to convert between a color and grayscale image, so your results using <code class="language-plaintext highlighter-rouge">skimage</code> may differ from results using other libraries or programming languages.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">I_pepper_gray</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">color</span><span class="p">.</span><span class="n">rgb2gray</span><span class="p">(</span><span class="n">I_pepper</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="-your-turn---6"><span style="color:Green"> Your turn:  </span></h2>
<p>What are the dimensions of <code class="language-plaintext highlighter-rouge">I_pepper_gray</code>?  How many channels does it have?  What is the variable type?  What are the max and min values?</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>

<h3 id="a-note-about-float-valued-images">A note about float-valued images</h3>
<p>You will probably have noticed that the variable <code class="language-plaintext highlighter-rouge">I_pepper_gray</code> is now a float-valued array, and that the range is now within $[0,1]$.  This is another common range for images.  Some functions, e.g., functions that write out to standard image formats, may expect <code class="language-plaintext highlighter-rouge">uint8</code> variables.  You can always cast back to <code class="language-plaintext highlighter-rouge">uint8</code> as needed, e.g., <code class="language-plaintext highlighter-rouge">I_pepper_gray_uint8=(I_pepper_gray*255).astype('uint8')</code>.</p>

<p>A common issue in image processing is a mismatch between the expected and actual variable type and/or intensity range.  If a function is expecting a <code class="language-plaintext highlighter-rouge">float</code> in the range $[0,1]$ and gets instead a <code class="language-plaintext highlighter-rouge">uint8</code> in the range $[0,255]$, unexpected things can happen.  A non-exhaustive list of some of the issues you might encounter:</p>
<ul>
  <li>The code will throw an error.</li>
  <li>The code will intelligently convert between the variable types (but this might mean you receive a different intensity range back from the code).</li>
  <li>The code will unintelligently convert between the variable types.</li>
  <li>You accidentally end up performing integer arithmetic instead of floating-point arithmentic.  This is a particularly fun one to track down.</li>
</ul>

<h2 id="-your-turn---7"><span style="color:Green"> Your turn:  </span></h2>
<p>Display this new grayscale image <code class="language-plaintext highlighter-rouge">I_pepper_gray</code>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>

<h2 id="32-grayscale-to-color">3.2 Grayscale to Color</h2>
<p>We can similarly convert a grayscale image to a color image using a standard command included in Scikit-Image.  It is important to note that this conversion is really just creation of an image with a third dimension.  Each of the color channels will be identical since we cannot infer color from solely a grayscale image.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">I_camera_rgb</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">color</span><span class="p">.</span><span class="n">gray2rgb</span><span class="p">(</span><span class="n">I_camera</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="-your-turn---8"><span style="color:Green"> Your turn:  </span></h2>
<p>What are the dimensions of <code class="language-plaintext highlighter-rouge">I_camera_rgb</code>?  How many channels does it have?  What is the variable type?  What are the max and min values?</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>

<h2 id="-your-turn---9"><span style="color:Green"> Your turn:  </span></h2>
<p>We expect that the three color channels in this <code class="language-plaintext highlighter-rouge">I_camera_rgb</code> image are identical.  Print out a small portion of the image to verify this to yourself.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>

<h2 id="-your-turn---10"><span style="color:Green"> Your turn:  </span></h2>
<p>Display this new RGB image <code class="language-plaintext highlighter-rouge">I_camera_rgb</code>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>

<h3 id="a-note-about-why-we-might-convert-a-grayscale-image-to-a-color-image">A note about why we might convert a grayscale image to a “color” image</h3>
<p>We note, unsurprisingly, that the <code class="language-plaintext highlighter-rouge">I_camera_rgb</code> still appears as a grayscale image.  It just happens to have 3 identical color channels.  In the meantime, we may be using three times the space to represent this image, but the fact that it now has 3 color channels instead of 1 will be key when we begin studying deep learning networks.</p>

<h1 id="33-cropping">3.3 Cropping</h1>
<p>Suppose that we have a network that expects a $256\times256$ image as input, i.e., the dimensionality of the <code class="language-plaintext highlighter-rouge">cameraman.png</code> image.  If we want to input <code class="language-plaintext highlighter-rouge">peppers.png</code> we have two problems: it has three color channels and it is of spatial dimension $384\times512$.  We know that we can convert the RGB image to a grayscale image.  Now we have to figure out how to rescale the spatial dimensions</p>

<p>If we crop the image, we choose some $256\times256$ pixels to retain.  For example if we kept the upper left corner of the image, we would have an image such as follows.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">I_pepper_gray_crop</span> <span class="o">=</span> <span class="n">I_pepper_gray</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">256</span><span class="p">,</span><span class="mi">0</span><span class="p">:</span><span class="mi">256</span><span class="p">]</span>
<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">20</span><span class="p">))</span> 
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">I_pepper_gray_crop</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s">'gray'</span><span class="p">)</span> 
<span class="n">plt</span><span class="p">.</span><span class="n">axis</span><span class="p">(</span><span class="s">'off'</span><span class="p">)</span> 
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Peppers, gray, cropped'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="Tutorial1_Image_Processing_Essentials_files/Tutorial1_Image_Processing_Essentials_75_0.png" alt="png" /></p>

<h3 id="cropping-removes-parts-of-the-image">Cropping removes parts of the image</h3>
<p>We note, unsurprisingly, that we have completely removed parts of the pepper image.</p>

<h1 id="34-resizing">3.4 Resizing</h1>
<p>What if the <code class="language-plaintext highlighter-rouge">peppers.png</code> image had fewer than 256 pixels?  What if we are unhappy with the loss of information associated with cropping?  Here we can use an image interpolation from the Scikit-Image transform library.  We can use the <code class="language-plaintext highlighter-rouge">skimage.transform.resize</code> function to resize the image.  In the following syntax, we are asking the function to resize <code class="language-plaintext highlighter-rouge">I_pepper_gray</code> to a size $256\times256$ pixels.</p>

<p>We note that there are many options to the resize command, including specification of what form of interpolation to use, whether to anti-alias filter, and different means of specifying the scale of the output.  See <code class="language-plaintext highlighter-rouge">help(skimage.transform.resize)</code> for more information.  The syntax used here assumes defaults for all parameters (a good starting point) and provides the expected scale of the output image in an easy to understand tuple that consists of the spatial dimensions in pixels.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">I_pepper_gray_resize</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">transform</span><span class="p">.</span><span class="n">resize</span><span class="p">(</span><span class="n">I_pepper_gray</span><span class="p">,</span> <span class="p">(</span><span class="mi">256</span><span class="p">,</span><span class="mi">256</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">20</span><span class="p">))</span> 
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">I_pepper_gray_resize</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s">'gray'</span><span class="p">)</span> 
<span class="n">plt</span><span class="p">.</span><span class="n">axis</span><span class="p">(</span><span class="s">'off'</span><span class="p">)</span> 
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Peppers, gray, resized'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="Tutorial1_Image_Processing_Essentials_files/Tutorial1_Image_Processing_Essentials_78_0.png" alt="png" /></p>

<h3 id="resizing-can-distort-the-aspect-ratio">Resizing can distort the aspect ratio</h3>
<p>Here we note that we have distorted the aspect ratio of the original <code class="language-plaintext highlighter-rouge">peppers.png</code> image.  In some applications this may not matter and in others it might matter a great deal.  In general, depending on the application, you may want to consider a combination of resizing and cropping.</p>

<h1 id="35-combining-cropping-and-resizing">3.5 Combining Cropping and Resizing</h1>

<h2 id="-your-turn---11"><span style="color:Green"> Your turn:  </span></h2>
<p>Combine cropping and resizing to yield a $256\times256$ pixel grayscale peppers image that you think retains the majority of the original “intent” of the image.  Note–there is no “right” answer here…</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>

<h2 id="-your-turn---12"><span style="color:Green"> Your turn:  </span></h2>
<p>How would you reconfigure the <code class="language-plaintext highlighter-rouge">cameraman</code> image to be the $384\times512\times3$ size of <code class="language-plaintext highlighter-rouge">peppers</code>?  Would you find this an easier conversion to make or a more difficult one?  Note–there is no “right” answer here either…</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>

<h1 id="section-4-filtering-images">Section 4: Filtering Images</h1>
<p>We will find that a key element of convolutional neural networks (CNNs) is a convolutional layer.  It is thus critical that we understand the basics of image convolution and how to interpret those results.</p>

<p>Convolution is the means to filter an image in the spatial domain.  This requires the definition of a filter kernel.  The filter kernel is a 2D or 3D array of filter coefficients, generally much smaller in spatial extent than the image.</p>

<h2 id="41-low-pass-smoothing-filters">4.1 Low Pass (Smoothing) Filters</h2>
<p>Many commonly used image filters are defined in <code class="language-plaintext highlighter-rouge">scipy.ndimage</code>.  Here, we explore how to explicity define a filter kernel and convolve that kernel with an image.  This will prepare us better to interpret the convolutional layers in CNNs.  We will use the <code class="language-plaintext highlighter-rouge">ndimage.filters.convolve</code> function here.</p>

<h3 id="411-define-the-filter-kernels">4.1.1 Define the filter kernels</h3>
<p>We define two filters <code class="language-plaintext highlighter-rouge">h1</code> and <code class="language-plaintext highlighter-rouge">h2</code>.  These are very simple lowpass (smoothing) filters where all the coefficients are equal in value and are normalized such that their sum is 1.  It is generally common practice to use odd-sized filters.  This is because there is an ambiguity in determining the “center” of an even-sized filter.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">h1</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="mf">9.</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="n">h2</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="mf">25.</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
</code></pre></div></div>

<h3 id="412-convolving-the-filter-kernels-with-an-image">4.1.2 Convolving the filter kernels with an image</h3>
<p>We compute the filtered output by convolving the image <code class="language-plaintext highlighter-rouge">I_camera</code> with each of the filter kernels using <code class="language-plaintext highlighter-rouge">ndimage.filters.convolve</code>.  We then visualize the filtered images.  We cast the image <code class="language-plaintext highlighter-rouge">I_camera</code> as a <code class="language-plaintext highlighter-rouge">float</code> to avoid integer arithmetic in the convolution operations.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">I_camera_h1</span> <span class="o">=</span> <span class="n">ndimage</span><span class="p">.</span><span class="n">filters</span><span class="p">.</span><span class="n">convolve</span><span class="p">(</span><span class="n">I_camera</span><span class="p">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">),</span> <span class="n">h1</span><span class="p">)</span>
<span class="n">I_camera_h2</span> <span class="o">=</span> <span class="n">ndimage</span><span class="p">.</span><span class="n">filters</span><span class="p">.</span><span class="n">convolve</span><span class="p">(</span><span class="n">I_camera</span><span class="p">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">),</span> <span class="n">h2</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">20</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">I_camera</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s">'gray'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">axis</span><span class="p">(</span><span class="s">'off'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Original'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">I_camera_h1</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s">'gray'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">axis</span><span class="p">(</span><span class="s">'off'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'h1'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">I_camera_h2</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s">'gray'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">axis</span><span class="p">(</span><span class="s">'off'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'h2'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="Tutorial1_Image_Processing_Essentials_files/Tutorial1_Image_Processing_Essentials_90_0.png" alt="png" /></p>

<h2 id="-your-turn---13"><span style="color:Green"> Your turn:  </span></h2>
<p>What effect has each of the filters <code class="language-plaintext highlighter-rouge">h1</code> and <code class="language-plaintext highlighter-rouge">h2</code> had on the image?</p>

<h2 id="42-high-pass-edge-enhancing-filters">4.2 High Pass (Edge Enhancing) Filters</h2>

<h3 id="421-define-the-filter-kernels">4.2.1 Define the filter kernels</h3>
<p>We define two filters <code class="language-plaintext highlighter-rouge">h3</code> and <code class="language-plaintext highlighter-rouge">h4</code>.  These are very simple highpass (edge enhancing) filters called the Sobel filters.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">h3</span> <span class="o">=</span> <span class="p">[[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">],[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">]]</span>
<span class="n">h4</span> <span class="o">=</span> <span class="p">[[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">],[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]]</span>
</code></pre></div></div>

<h3 id="422-convolving-the-filter-kernels-with-an-image">4.2.2 Convolving the filter kernels with an image</h3>
<p>We compute the filtered output by convolving the image <code class="language-plaintext highlighter-rouge">I_camera</code> with each of the filter kernels.  We again cast the image <code class="language-plaintext highlighter-rouge">I_camera</code> as a <code class="language-plaintext highlighter-rouge">float</code> to avoid integer arithmetic in the convolution operations.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">I_camera_h3</span> <span class="o">=</span> <span class="n">ndimage</span><span class="p">.</span><span class="n">filters</span><span class="p">.</span><span class="n">convolve</span><span class="p">(</span><span class="n">I_camera</span><span class="p">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">),</span> <span class="n">h3</span><span class="p">)</span>
<span class="n">I_camera_h4</span> <span class="o">=</span> <span class="n">ndimage</span><span class="p">.</span><span class="n">filters</span><span class="p">.</span><span class="n">convolve</span><span class="p">(</span><span class="n">I_camera</span><span class="p">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">),</span> <span class="n">h4</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="a-note-on-filtered-images-that-have-negative-values">A note on filtered images that have negative values</h3>
<p>It is common that filtered images may end up with intensity values outside of the original range.  In this case, the image <code class="language-plaintext highlighter-rouge">I_camera</code> was in the range $[0,255]$.  If we look at the range of the filtered images, we find that the filtered images now span a much larger range:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="s">'Max and min values of the h3 filtered image:'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'    Min: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">I_camera_h3</span><span class="p">.</span><span class="nb">min</span><span class="p">()))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'    Max: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">I_camera_h3</span><span class="p">.</span><span class="nb">max</span><span class="p">()))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Max and min values of the h4 filtered image:'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'    Min: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">I_camera_h4</span><span class="p">.</span><span class="nb">min</span><span class="p">()))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'    Max: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">I_camera_h4</span><span class="p">.</span><span class="nb">max</span><span class="p">()))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Max and min values of the h3 filtered image:
    Min: -861.0
    Max: 893.0
Max and min values of the h4 filtered image:
    Min: -900.0
    Max: 882.0
</code></pre></div></div>

<p>The Sobel filters are designed to approximate the first derivative of the image.  As such, we might expect that the derivative (think slope) will potentially be positive or negative and could span a different absolute range than the original $[0,255]$.  We can get a better sense of the edge enhancement capabilities of <code class="language-plaintext highlighter-rouge">h3</code> and <code class="language-plaintext highlighter-rouge">h4</code> if we look only at the positive values.  Looking only at the positive values rather than the absolute value will be more consistent with the activation function we will use in convolutional neural networks.  We first clip all negative values in the images to zero and then visualize the filtered output.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">20</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">I_camera</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s">'gray'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">axis</span><span class="p">(</span><span class="s">'off'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Original'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="n">I_camera_h3</span><span class="p">[</span><span class="n">I_camera_h3</span><span class="o">&lt;</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">I_camera_h3</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s">'gray'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">axis</span><span class="p">(</span><span class="s">'off'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'h3'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="n">I_camera_h4</span><span class="p">[</span><span class="n">I_camera_h4</span><span class="o">&lt;</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">I_camera_h4</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s">'gray'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">axis</span><span class="p">(</span><span class="s">'off'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'h4'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="Tutorial1_Image_Processing_Essentials_files/Tutorial1_Image_Processing_Essentials_101_0.png" alt="png" /></p>

<p>When we focus only on the positive values of the filtered output, we see that the majority of the filtered image is now close to a value of 0 (i.e., black), and it is only at the edges of the image objects that we see a response (i.e., lighter values). We see that <code class="language-plaintext highlighter-rouge">h3</code> has enhanced edges oriented in a horizontal direction and <code class="language-plaintext highlighter-rouge">h4</code> has enhanced edges oriented in a vertical direction.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>

        
      </section>

      <footer class="page__meta">
        
        


        
      </footer>

      

      

    </div>

    
  </article>

  
  
</div>
    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><form onsubmit="return googleCustomSearchExecute();" id="cse-search-box-form-id">
    <input type="search" id="cse-search-input-box-id" aria-placeholder="Enter your search term..." class="search-input" tabindex="-1" placeholder="Enter your search term..." />
    </form>
    <div id="results" class="results">
        <gcse:searchresults-only></gcse:searchresults-only>
    </div></div>

      </div>
    
    
    <div class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->

        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    
    
      <li><a href="https://twitter.com/isugif"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
    
    
    
      <li><a href="https://github.com/https://github.com/isugenomics"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
    
    
    
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2024 Geospatial Workbook</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>
  <script src="https://use.fontawesome.com/releases/v5.0.13/js/all.js"></script>


<script>
  (function () {
    var cx = '009853197685285203469:nsvri1pa88d';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();

  function googleCustomSearchExecute() {
    var input = document.getElementById('cse-search-input-box-id');
    var element = google.search.cse.element.getElement('searchresults-only0');
    if (input.value == '') {
      element.clearAllResults();
    } else {
      element.execute(input.value);
    }
    return false;
  }

  
</script>




<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" defer
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>




  </body>
</html>
